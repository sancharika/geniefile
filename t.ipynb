{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "from streamlit_jupyter import StreamlitPatcher, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = StreamlitPatcher()\n",
    "sp.jupyter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Contact Sancharika Debnath 9477230267 (Mobile) sancharikadebnath@gmail.com Passionate Data Scientist || Machine Learning|| AI || Innovator in Emerging Technologies www.linkedin.com/in/sancharika- Kolkata, West Bengal, India debnath (LinkedIn) huggingface.co/sancharikadebnath (Portfolio) Summary github.com/sancharika/ (Portfolio) Welcome to my professional journey! I'm Sancharika Debnath, a Top Skills dynamic Data Scientist driven by a fervent enthusiasm for leveraging cutting-edge technology to craft innovative solutions. With a solid RAG Model foundation in data science and backend development, I specialize in Vector Databases translating complex data into actionable insights and robust systems. Prompt Engineering Certifications My career has been an exhilarating exploration of possibilities, from developing agile event systems integrated with facial recognition Machine Learning for seamless attendance management to architecting custom APIs Problem Solving (Intermediate) for large-scale data retrieval. At Giggr Technology, I spearheaded Introduction to C++ GAIT Online Program IT the development of a transformative event system, achieving an Professional - Silver impressive accuracy rate of 87.4% through a blend of OpenCV, AWS Machine Learning Engineer YOLO, and Deep-Face technologies. Nanodegree In my tenure at Leapon, I honed my backend development skills, Publications crafting tailored solutions using Python, Django, and AWS to Hyperspectral Image Compression optimize website performance and enhance user experiences. This using Modified Convolutional Autoencoder experience instilled in me the importance of precision and scalability in every project I undertake. As a Data Science Intern at Maersk Global Service Centres, I delved into predictive analytics and optimization, devising algorithms to forecast container turn times and enhance logistical efficiency. My passion for exploring the intersections of data and technology led me to HighRadius Corporation, where I pioneered a regression invoice prediction system, leveraging machine learning models for streamlined financial operations. Outside of the corporate realm, I'm an avid contributor to the tech community, with publications in esteemed journals such as the International Journal of Computational Intelligence Systems. My recent research on Hyperspectral Image Compression Page 1 of 4and Classification, achieving a remarkable accuracy of 99.8%, underscores my dedication to pushing the boundaries of innovation. I thrive in collaborative environments where creativity meets technical prowess, and I'm eager to connect with like-minded professionals and organizations committed to driving meaningful change through data-driven insights. Let's embark on a journey of innovation together! Experience Data Scientist February 2024 - Present (4 months) Giggr - The Future of Work Data Scientist July 2023 - February 2024 (8 months) Bengaluru, Karnataka, India • Responsibility: Integrated experience in artificial intelligence, data science and graph database architecture to deliver comprehensive solutions – Engineered an innovative data-driven event system integrating facial recognition for attendance tracking and object detection for gamification purposes. (Accuracy: 87.4) – Integrated GPS functionality to facilitate user navigation to the event venue, enhancing overall user experience and convenience. – Guided the team in developing a Neo4j architecture, quickly acquiring intermediate proficiency. Collaboratively integrated it into the project ecosystem, enhancing data management and analytics capabilities while teamwork. – Crafted and worked independently to create custom public API from scratch, prioritizing data security while utilizing S3 and Elasticsearch to efficiently search through a dataset of over 1.3 million education institutes across India. – Designed and implemented a quiz chatbot for digital maturity evaluation using Dialogflow, featuring a sophisticated scoring system and seamless Firebase integration, enriching user interaction and data functionality. Leapon Back End Developer February 2023 - June 2023 (5 months) Remote Page 2 of 4• Responsibility: Constructed and developed the Backend architecture for the entire website personalised for 50+ advisor connectivity. – Developed REST APIs to facilitate seamless communication between the frontend and backend systems and integrated A/B testing frameworks to analyze user interactions and optimize feature performance. – Utilized CI/CD pipelines to streamline the development process, ensuring rapid and reliable deployment of new features and updates, thereby enhancing advisor networking by up to 60% with effective decision support. A.P. Moller - Maersk Data Science Intern July 2022 - February 2023 (8 months) Bengaluru, Karnataka, India Worked on various data science related and web development related real life projects. • Created an end-to-end web application for pre-booking seats in office premises using springboot, next.js and internal UI developer, Anchor UI. • Clustering of ports based on predominant features using different clustering techniques ( Best Model : Gaussian Mixture ). • Prediction of container turn time considering time series effects of the data. • Prediction of change in attachment ratio percentage using various AutoML ( Best Model : FLAML). HighRadius Data Sceince Intern January 2022 - April 2022 (4 months) Bhubaneswar, Odisha, India Developed an Automation invoice prediction system. • Using machine learning algorithms (Best Model: XGBoost) for prediction of invoice clearance date. • JDBC, and React JS was used on a real world transaction database for an interactive web page. (Accuracy: 76.15) The Sparks Foundation Data Science & Business Analytics Intern July 2021 - August 2021 (2 months) Page 3 of 4• Prediction of student performance Using Supervised Machine Learning Algorithm • Achieved accuracy rate of 95.5 Ativeer Tech Data Science Intern June 2021 - July 2021 (2 months) • Product appending in the website back-end • Used WordPress and Wix to represent product details for more than 150+ products Education Kalinga Institute of Industrial Technology, Bhubaneswar 4th, year, Information Technology · (July 2019 - July 2023) Kendriya Vidyalaya · (2007 - 2019) Page 4 of 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from features import *\n",
    "from components import docLoader, functions\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pinecone import Pinecone as pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders.telegram import text_to_docs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize CareerEnchanter\n",
    "class CareerEnchanter(object):\n",
    "    def __init__(self, title=\"CareerEnchanter\"):\n",
    "        self.title = title\n",
    "\n",
    "    @staticmethod\n",
    "    def model():\n",
    "        genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "        return ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# Initialize CareerEnchanter instance\n",
    "enchanter = CareerEnchanter()\n",
    "func = functions.Functions()\n",
    "text = text_to_docs(text)\n",
    "\n",
    "model_id = \"intfloat/multilingual-e5-large\"\n",
    "pc = pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    ")\n",
    "index_name=\"geniefile-index\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_document = \"## Introduction\\n\\nWelcome to the whimsical world of the \"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"##\", \"Header 2\")\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on, strip_headers=False\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_data(docs,chunk_size=10000,chunk_overlap=5000):\n",
    "            text_splitter=RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "            doc=text_splitter.split_documents(docs)\n",
    "            return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"\n",
    "THE\n",
    "ALCHEMISTPAULO COELHO\n",
    "TRANSLATED BY ALAN R. CLARKEContents\n",
    "INTRODUCTION\n",
    "I remember receiving a letter from the\n",
    "American publisher Harper Collins…\n",
    "PROLOGUE\n",
    "The alchemist picked up a book that someone\n",
    "in the…\n",
    "O\n",
    "NE\n",
    "The boy’s name was Santiago. Dusk was\n",
    "falling as the…T\n",
    "WO\n",
    "The boy had been working for the crystal\n",
    "merchant for…\n",
    "EPILOGUE\n",
    "The boy reached the small, abandoned\n",
    "church just as night…\n",
    "ABOUT THE AUTHOR\n",
    "INTERNATIONAL ACCLAIM\n",
    "BOOKS BY PAULO COELHOCREDITS\n",
    "COVER\n",
    "COPYRIGHT\n",
    "ABOUT THE PUBLISHERTEN YEARS ON\n",
    "I A publisher Harper\n",
    "REMEMBER RECEIVING A LETTER FROM THE MERICAN\n",
    "Collins that said that: “reading The Alchemist was like getting up at\n",
    "dawn and seeing the sun rise while the rest of the world still slept.” I\n",
    "went outside, looked up at the sky, and thought to myself: “So, the\n",
    "book is going to be published in English!” At the time, I was\n",
    "struggling to establish myself as a writer and to follow my path\n",
    "despite all the voices telling me it was impossible.\n",
    "And little by little, my dream was becoming reality. Ten, a\n",
    "hundred, a thousand, a million copies sold in America. One day, a\n",
    "Brazilian journalist phoned to say that President Clinton had been\n",
    "photographed reading the book. Some time later, when I was in\n",
    "Turkey, I opened the magazine Vanity Fair and there was Julia\n",
    "Roberts declaring that she adored the book. Walking alone down a\n",
    "street in Miami, I heard a girl telling her mother: “You must read\n",
    "The Alchemist!”\n",
    "The book has been translated into fifty-six languages, has sold\n",
    "more than twenty million copies, and people are beginning to ask:\n",
    "What’s the secret behind such a huge success?\n",
    "The only honest response is: I don’t know. All I know is that, like\n",
    "Santiago the shepherd boy, we all need to be aware of our personal\n",
    "calling. What is a personal calling? It is God’s blessing, it is the path\n",
    "that God chose for you here on Earth. Whenever we do something\n",
    "that fills us with enthusiasm, we are following our legend. However,\n",
    "we don’t all have the courage to confront our own dream.Why?\n",
    "There are four obstacles. First: we are told from childhood\n",
    "onward that everything we want to do is impossible. We grow up\n",
    "with this idea, and as the years accumulate, so too do the layers of\n",
    "prejudice, fear, and guilt. There comes a time when our personal\n",
    "calling is so deeply buried in our soul as to be invisible. But it’s still\n",
    "there.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTHE\\nALCHEMISTPAULO COELHO\\nTRANSLATED BY ALAN R. CLARKEContents\\nINTRODUCTION\\nI remember receiving a letter from the\\nAmerican publisher Harper Collins…\\nPROLOGUE\\nThe alchemist picked up a book that someone\\nin the…\\nO\\nNE\\nThe boy’s name was Santiago. Dusk was\\nfalling as the…T\\nWO\\nThe boy had been working for the crystal\\nmerchant for…\\nEPILOGUE\\nThe boy reached the small, abandoned\\nchurch just as night…\\nABOUT THE AUTHOR\\nINTERNATIONAL ACCLAIM\\nBOOKS BY PAULO COELHOCREDITS\\nCOVER\\nCOPYRIGHT\\nABOUT THE PUBLISHERTEN YEARS ON\\nI A publisher Harper\\nREMEMBER RECEIVING A LETTER FROM THE MERICAN\\nCollins that said that: “reading The Alchemist was like getting up at\\ndawn and seeing the sun rise while the rest of the world still slept.” I\\nwent outside, looked up at the sky, and thought to myself: “So, the\\nbook is going to be published in English!” At the time, I was\\nstruggling to establish myself as a writer and to follow my path\\ndespite all the voices telling me it was impossible.\\nAnd little by little, my dream was becoming reality. Ten, a\\nhundred, a thousand, a million copies sold in America. One day, a\\nBrazilian journalist phoned to say that President Clinton had been\\nphotographed reading the book. Some time later, when I was in\\nTurkey, I opened the magazine Vanity Fair and there was Julia\\nRoberts declaring that she adored the book. Walking alone down a\\nstreet in Miami, I heard a girl telling her mother: “You must read\\nThe Alchemist!”\\nThe book has been translated into fifty-six languages, has sold\\nmore than twenty million copies, and people are beginning to ask:\\nWhat’s the secret behind such a huge success?\\nThe only honest response is: I don’t know. All I know is that, like\\nSantiago the shepherd boy, we all need to be aware of our personal\\ncalling. What is a personal calling? It is God’s blessing, it is the path\\nthat God chose for you here on Earth. Whenever we do something\\nthat fills us with enthusiasm, we are following our legend. However,\\nwe don’t all have the courage to confront our own dream.Why?\\nThere are four obstacles. First: we are told from childhood\\nonward that everything we want to do is impossible. We grow up\\nwith this idea, and as the years accumulate, so too do the layers of\\nprejudice, fear, and guilt. There comes a time when our personal\\ncalling is so deeply buried in our soul as to be invisible. But it’s still\\nthere.\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='THE\\nALCHEMISTPAULO COELHO\\nTRANSLATED BY ALAN R. CLARKEContents\\nINTRODUCTION\\nI remember receiving a letter from the\\nAmerican publisher Harper Collins…\\nPROLOGUE\\nThe alchemist picked up a book that someone\\nin the…\\nO\\nNE\\nThe boy’s name was Santiago. Dusk was\\nfalling as the…T\\nWO\\nThe boy had been working for the crystal\\nmerchant for…\\nEPILOGUE\\nThe boy reached the small, abandoned\\nchurch just as night…\\nABOUT THE AUTHOR\\nINTERNATIONAL ACCLAIM\\nBOOKS BY PAULO COELHOCREDITS\\nCOVER\\nCOPYRIGHT\\nABOUT THE PUBLISHERTEN YEARS ON\\nI A publisher Harper\\nREMEMBER RECEIVING A LETTER FROM THE MERICAN\\nCollins that said that: “reading The Alchemist was like getting up at\\ndawn and seeing the sun rise while the rest of the world still slept.” I\\nwent outside, looked up at the sky, and thought to myself: “So, the', metadata={'page': 1, 'chunk': 0, 'source': '1-0'}), Document(page_content='book is going to be published in English!” At the time, I was\\nstruggling to establish myself as a writer and to follow my path\\ndespite all the voices telling me it was impossible.\\nAnd little by little, my dream was becoming reality. Ten, a\\nhundred, a thousand, a million copies sold in America. One day, a\\nBrazilian journalist phoned to say that President Clinton had been\\nphotographed reading the book. Some time later, when I was in\\nTurkey, I opened the magazine Vanity Fair and there was Julia\\nRoberts declaring that she adored the book. Walking alone down a\\nstreet in Miami, I heard a girl telling her mother: “You must read\\nThe Alchemist!”\\nThe book has been translated into fifty-six languages, has sold\\nmore than twenty million copies, and people are beginning to ask:', metadata={'page': 1, 'chunk': 1, 'source': '1-1'})]\n",
      "[Document(page_content='What’s the secret behind such a huge success?\\nThe only honest response is: I don’t know. All I know is that, like\\nSantiago the shepherd boy, we all need to be aware of our personal\\ncalling. What is a personal calling? It is God’s blessing, it is the path\\nthat God chose for you here on Earth. Whenever we do something\\nthat fills us with enthusiasm, we are following our legend. However,\\nwe don’t all have the courage to confront our own dream.Why?\\nThere are four obstacles. First: we are told from childhood\\nonward that everything we want to do is impossible. We grow up\\nwith this idea, and as the years accumulate, so too do the layers of\\nprejudice, fear, and guilt. There comes a time when our personal\\ncalling is so deeply buried in our soul as to be invisible. But it’s still\\nthere.', metadata={'page': 1, 'chunk': 2, 'source': '1-2'})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='THE\\nALCHEMISTPAULO COELHO\\nTRANSLATED BY ALAN R. CLARKEContents\\nINTRODUCTION\\nI remember receiving a letter from the\\nAmerican publisher Harper Collins…\\nPROLOGUE\\nThe alchemist picked up a book that someone\\nin the…\\nO\\nNE\\nThe boy’s name was Santiago. Dusk was\\nfalling as the…T\\nWO\\nThe boy had been working for the crystal\\nmerchant for…\\nEPILOGUE\\nThe boy reached the small, abandoned\\nchurch just as night…\\nABOUT THE AUTHOR\\nINTERNATIONAL ACCLAIM\\nBOOKS BY PAULO COELHOCREDITS\\nCOVER\\nCOPYRIGHT\\nABOUT THE PUBLISHERTEN YEARS ON\\nI A publisher Harper\\nREMEMBER RECEIVING A LETTER FROM THE MERICAN\\nCollins that said that: “reading The Alchemist was like getting up at\\ndawn and seeing the sun rise while the rest of the world still slept.” I\\nwent outside, looked up at the sky, and thought to myself: “So, the', metadata={'page': 1, 'chunk': 0, 'source': '1-0'}),\n",
       " Document(page_content='book is going to be published in English!” At the time, I was\\nstruggling to establish myself as a writer and to follow my path\\ndespite all the voices telling me it was impossible.\\nAnd little by little, my dream was becoming reality. Ten, a\\nhundred, a thousand, a million copies sold in America. One day, a\\nBrazilian journalist phoned to say that President Clinton had been\\nphotographed reading the book. Some time later, when I was in\\nTurkey, I opened the magazine Vanity Fair and there was Julia\\nRoberts declaring that she adored the book. Walking alone down a\\nstreet in Miami, I heard a girl telling her mother: “You must read\\nThe Alchemist!”\\nThe book has been translated into fifty-six languages, has sold\\nmore than twenty million copies, and people are beginning to ask:', metadata={'page': 1, 'chunk': 1, 'source': '1-1'}),\n",
       " Document(page_content='What’s the secret behind such a huge success?\\nThe only honest response is: I don’t know. All I know is that, like\\nSantiago the shepherd boy, we all need to be aware of our personal\\ncalling. What is a personal calling? It is God’s blessing, it is the path\\nthat God chose for you here on Earth. Whenever we do something\\nthat fills us with enthusiasm, we are following our legend. However,\\nwe don’t all have the courage to confront our own dream.Why?\\nThere are four obstacles. First: we are told from childhood\\nonward that everything we want to do is impossible. We grow up\\nwith this idea, and as the years accumulate, so too do the layers of\\nprejudice, fear, and guilt. There comes a time when our personal\\ncalling is so deeply buried in our soul as to be invisible. But it’s still\\nthere.', metadata={'page': 1, 'chunk': 2, 'source': '1-2'})]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = chunk_data(text_to_docs(text))\n",
    "texts = [doc.page_content for doc in data]\n",
    "batch_size = 2\n",
    "for i in range(0, len(data), batch_size):\n",
    "                data_ = data[i: i+batch_size]\n",
    "                print(data_)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogleGenerativeAIEmbeddings(model='models/embedding-001', task_type=None, google_api_key=None, credentials=None, client_options=None, transport=None, request_options=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 \n",
      "THE\n",
      "ALCHEMISTPAULO COELHO\n",
      "TRANSLATED BY ALAN R. CLARKEContents\n",
      "INTRODUCTION\n",
      "I remember receiving a letter from the\n",
      "American pub\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E425940>\n",
      "128 lisher Harper Collins…\n",
      "PROLOGUE\n",
      "The alchemist picked up a book that someone\n",
      "in the…\n",
      "O\n",
      "NE\n",
      "The boy’s name was Santiago. Dusk was\n",
      "f\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E8AB350>\n",
      "128 alling as the…T\n",
      "WO\n",
      "The boy had been working for the crystal\n",
      "merchant for…\n",
      "EPILOGUE\n",
      "The boy reached the small, abandoned\n",
      "church j\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E4244A0>\n",
      "128 ust as night…\n",
      "ABOUT THE AUTHOR\n",
      "INTERNATIONAL ACCLAIM\n",
      "BOOKS BY PAULO COELHOCREDITS\n",
      "COVER\n",
      "COPYRIGHT\n",
      "ABOUT THE PUBLISHERTEN YEARS O\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E4265D0>\n",
      "128 N\n",
      "I A publisher Harper\n",
      "REMEMBER RECEIVING A LETTER FROM THE MERICAN\n",
      "Collins that said that: “reading The Alchemist was like gett\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E4244A0>\n",
      "128 ing up at\n",
      "dawn and seeing the sun rise while the rest of the world still slept.” I\n",
      "went outside, looked up at the sky, and thoug\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E5400B0>\n",
      "128 ht to myself: “So, the\n",
      "book is going to be published in English!” At the time, I was\n",
      "struggling to establish myself as a writer \n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E15E9F0>\n",
      "128 and to follow my path\n",
      "despite all the voices telling me it was impossible.\n",
      "And little by little, my dream was becoming reality. \n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E15FF80>\n",
      "128 Ten, a\n",
      "hundred, a thousand, a million copies sold in America. One day, a\n",
      "Brazilian journalist phoned to say that President Clint\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E8AB110>\n",
      "128 on had been\n",
      "photographed reading the book. Some time later, when I was in\n",
      "Turkey, I opened the magazine Vanity Fair and there wa\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E540530>\n",
      "128 s Julia\n",
      "Roberts declaring that she adored the book. Walking alone down a\n",
      "street in Miami, I heard a girl telling her mother: “Yo\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E15FF80>\n",
      "128 u must read\n",
      "The Alchemist!”\n",
      "The book has been translated into fifty-six languages, has sold\n",
      "more than twenty million copies, and\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E4244A0>\n",
      "128  people are beginning to ask:\n",
      "What’s the secret behind such a huge success?\n",
      "The only honest response is: I don’t know. All I kno\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E15E9F0>\n",
      "128 w is that, like\n",
      "Santiago the shepherd boy, we all need to be aware of our personal\n",
      "calling. What is a personal calling? It is Go\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E15F8F0>\n",
      "128 d’s blessing, it is the path\n",
      "that God chose for you here on Earth. Whenever we do something\n",
      "that fills us with enthusiasm, we ar\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E427B90>\n",
      "128 e following our legend. However,\n",
      "we don’t all have the courage to confront our own dream.Why?\n",
      "There are four obstacles. First: w\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E0A7F80>\n",
      "128 e are told from childhood\n",
      "onward that everything we want to do is impossible. We grow up\n",
      "with this idea, and as the years accumu\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E8ABFB0>\n",
      "128 late, so too do the layers of\n",
      "prejudice, fear, and guilt. There comes a time when our personal\n",
      "calling is so deeply buried in ou\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E15E9F0>\n",
      "49 r soul as to be invisible. But it’s still\n",
      "there.\n",
      "\n",
      "db: <langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5E8ABFB0>\n"
     ]
    }
   ],
   "source": [
    "docs = chunk_data(text_to_docs(text))\n",
    "document = [doc.page_content for doc in docs]\n",
    "for i in range(0, len(text), 128):\n",
    "            texts = text[i: i+128]\n",
    "            print(len(texts), texts)\n",
    "            docs = chunk_data(text_to_docs(text))\n",
    "            # embeddings = gemini_embeddings.embed_documents(texts)\n",
    "            db = FAISS.from_documents(docs, gemini_embeddings)\n",
    "            print(\"db:\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m gemini_embeddings \u001b[38;5;241m=\u001b[39m GoogleGenerativeAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/embedding-001\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m gemini_embeddings\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m----> 5\u001b[0m db \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(\u001b[43mdocs\u001b[49m, embeddings)\n\u001b[0;32m      6\u001b[0m db\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "embeddings = gemini_embeddings.embed_documents(texts)\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = func.chunk_data(docs=text)\n",
    "doc_chunks = func.convert_to_batches(document_chunks,100)\n",
    "texts = [d.page_content for d in document_chunks]\n",
    "# result = genai.embed_content(model=\"models/text-embedding-004\", content=embedding_text, task_type=\"retrieval_document\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name = model_id)\n",
    "\n",
    "# Load the document into our database\n",
    "Pinecone.from_documents(text, embeddings, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "\n",
    "for ids in index.list():\n",
    "    query = index.query(\n",
    "        id=ids[0], \n",
    "        \n",
    "        top_k=1,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    print(query['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import openai\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_community.document_loaders.telegram import text_to_docs\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from components import docLoader, functions\n",
    "\n",
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.indiatoday.in/business/story/explained-how-smaller-it-firms-are-stealing-the-spotlight-from-tcs-infosys-2542369-2024-05-22\"\n",
    "])\n",
    "# data = loaders.load() \n",
    "func = functions.Functions()\n",
    "\n",
    "data = text_to_docs(text)\n",
    "print(len(data))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "docs = func.chunk_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "db = FAISS.from_documents(docs, gemini_embeddings)\n",
    "file_path=\"saved_embeddings\"\n",
    "# saving the document in the vector store\n",
    "db.save_local(file_path)\n",
    "\n",
    "# reloading the documents form the vector store\n",
    "new_db = FAISS.load_local( folder_path =file_path, embeddings =gemini_embeddings,\n",
    "                          allow_dangerous_deserialization = True)\n",
    "\n",
    "# creating a retriver object \n",
    "retriever = new_db.as_retriever()\n",
    "\n",
    "# Initialise LLM with required params\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI( model= \"gemini-1.5-flash-latest\",\n",
    "                 temperature=0.3, top_p=0.85)\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever= retriever)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Prompt template to query Gemini\n",
    "llm_prompt_template = \"\"\"You are an assistant for question-answering tasks with advanced analytical and reasoning capabilities\n",
    "Use the following context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Keep the answer concise.\\n\n",
    "Question: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "\n",
    "print(llm_prompt)\n",
    "\n",
    "# OUTPUT:\n",
    "\"\"\" \n",
    "input_variables=['context', 'question'] template=\"You are an assistant for question-answering tasks with advanced analytical and reasoning capabilities\\nUse the following context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nKeep the answer concise.\\n\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"what are the top skills?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<langchain_community.docstore.in_memory.InMemoryDocstore at 0x1d1818a21b0>,\n",
       " {0: '8fe4fcb0-556e-45e7-9676-7ee608cef490',\n",
       "  1: '939276f7-9128-4e8e-b749-c1ec96734772',\n",
       "  2: 'dff55df3-505d-4e92-b1a0-288b5e3dfc5c',\n",
       "  3: 'dca83c14-8b8f-4d51-9d69-864bc78d089f',\n",
       "  4: 'b35411cb-1ca7-4cbe-93a6-1f84ab6fcb2a',\n",
       "  5: '97e0fa97-eaa4-4fe4-b162-48797cc3e67d',\n",
       "  6: '71080cba-5403-4759-b0a3-c60ce615c3c9',\n",
       "  7: '054a5706-5df7-4b85-8f35-f6b8d735e3f2',\n",
       "  8: 'd4415b47-ef05-4edc-a6ca-e2ff6a194045',\n",
       "  9: 'b0230537-bade-46bf-a67f-f45f3f530d1f',\n",
       "  10: 'e56b812f-7315-4569-b556-8ecf57082fed',\n",
       "  11: '250dfa5f-84e5-4a07-87f1-d5506208db4c',\n",
       "  12: '6fc4f309-2bd7-40bb-a5e9-b11ff117bdf5',\n",
       "  13: 'f8580efa-f473-40e0-af4e-2d0145af6e19',\n",
       "  14: '1afadb09-2790-44f7-9bcd-266488f03bc3',\n",
       "  15: '76ee6208-007f-499c-9ce2-4ab626af3822',\n",
       "  16: 'b8dfa93e-d778-4703-af31-fc5a12f6dd8e',\n",
       "  17: '0753a64a-00ea-47fd-acf1-9893f6009272',\n",
       "  18: 'cdd57174-f7ad-45d6-9854-1e01eea858ba',\n",
       "  19: '76c21db7-8670-4b89-b0f0-4607971e8c6c',\n",
       "  20: 'c2ecc542-471c-4d13-aa21-04a7b69a7f58',\n",
       "  21: 'd9357208-1a09-4100-95e5-a86b6a906dab',\n",
       "  22: '4397ff83-cfee-4517-9e16-1d557e7ae4d0',\n",
       "  23: '308d2374-8631-4f4d-bce2-d7ed891bea27',\n",
       "  24: '5bdfe835-2a97-4423-9ec7-c82c7a6a3c8e',\n",
       "  25: '56f50698-174c-464e-97ff-275a631cb21a',\n",
       "  26: '7ee5ce82-2986-4851-ab74-e74647616cf9',\n",
       "  27: '54fc1b8d-3a23-4847-9878-5e3b3ad80738',\n",
       "  28: '88c31e82-1451-49fc-9aa5-1c02ddeaac12',\n",
       "  29: '2f5a44dc-eea1-4675-988f-4e2eb75ca29d',\n",
       "  30: '165de3fe-bda3-4045-8c96-d1bcbb0260d9',\n",
       "  31: '82bd983f-a71e-4162-a997-3eb5614af30c',\n",
       "  32: '537806a6-21a4-468b-a64f-d7d5d4338e4e',\n",
       "  33: '22368824-a039-455c-bb2a-fc0b6c879cd1',\n",
       "  34: '2828315d-670f-4c55-b216-1c63e78020fb',\n",
       "  35: '7cd6f581-05b0-4b60-a1a3-ef08210a712a',\n",
       "  36: '77223f36-c12b-477e-b174-195b9c5adfce',\n",
       "  37: '74642a5f-9d93-4f72-bcbd-9ea4cf6691b2',\n",
       "  38: 'fe4fb7e8-2ca5-44ff-84e0-3ccab92f59dd',\n",
       "  39: 'db97dcf9-c537-4cfd-8442-4b52dad88c1f',\n",
       "  40: '15beec9f-ac05-4649-9961-9f43d963de1c',\n",
       "  41: '5734b577-18b8-4056-8450-33e6164c9945',\n",
       "  42: 'fa0a9744-ca2b-4e8d-96f5-7abbd986b082',\n",
       "  43: '619ffae3-dc61-4041-86aa-d217ca45bcfe',\n",
       "  44: '5d202542-7bbc-4da7-bf9d-94fbc9a39a47',\n",
       "  45: '9bfda07a-743e-4b52-bbdc-5e0abbcd0608',\n",
       "  46: 'c4af02a4-56ea-4532-870a-3c7d4a62fd73',\n",
       "  47: '8f78afbd-b8ad-49e0-97ce-ab9153b5bda0',\n",
       "  48: '7eff175d-3afc-4fd7-aa6a-8afb351279aa',\n",
       "  49: '2eebe0a3-854b-41d8-ab4b-58eca2305d78',\n",
       "  50: '72ee2c4f-9539-4840-9bb5-699bb2495c36',\n",
       "  51: '40a453c1-dade-489a-ae3f-38c20134bb79',\n",
       "  52: 'd2e6967d-b745-49fa-8c99-e38b671958bb',\n",
       "  53: '87f542c2-84bc-4cfc-b1a4-714243caf8ae',\n",
       "  54: 'cf0653bc-a363-487c-87ce-524262702dae',\n",
       "  55: 'd17d85ce-82cd-4c06-b771-0379e537bbda',\n",
       "  56: '13fb05fc-b415-4d7c-81b6-f10b37271721',\n",
       "  57: '5c31649e-497e-4ec5-9095-153263ff3e1e',\n",
       "  58: '6147a6f3-34f7-4456-ae31-e6816be850fe',\n",
       "  59: 'e8cc804f-2241-4c2a-bd20-b95c8792dd16',\n",
       "  60: '2d8c6015-c358-4224-ac83-de2c5d877973',\n",
       "  61: '948acda2-4266-4e71-a0cf-94e0cc40d80a',\n",
       "  62: '9e53df8e-3429-41bd-bc09-647168aeb337',\n",
       "  63: 'fb92510d-6969-4f5a-9f5a-a37761346658',\n",
       "  64: '11165ae3-8c8b-473f-9bde-3c62f30b23b7',\n",
       "  65: '1195ca0b-460b-4c29-86c9-b83e9c835b28',\n",
       "  66: 'd522c04b-0ca8-49c3-8ccc-e67b19e0ff18',\n",
       "  67: 'd5a13e3d-c9af-43ca-b6dd-099a36e73817',\n",
       "  68: 'efc8d0e5-b787-4e72-885d-22a44f523044',\n",
       "  69: '8ef7c2b2-b3f0-44eb-8755-86461db05f4f',\n",
       "  70: '006e0ed9-aed0-4d93-b510-1aba5fed5d48',\n",
       "  71: '0e0fb6b2-f8d1-43e0-80fa-17090a53a434',\n",
       "  72: 'b4976659-3409-4521-83f7-b7f2c51365a1',\n",
       "  73: '514defa1-2a00-48f0-b764-7c664258e26f',\n",
       "  74: 'b8906712-d827-4e5c-8382-931535933de8',\n",
       "  75: '6b987c24-ec79-4b5f-b4fe-d2bd934f9d1c',\n",
       "  76: '4f2fad66-4ce1-4655-93f8-a9137442e1cc',\n",
       "  77: '35e20532-145b-4b3b-b733-52577dbb5fb3',\n",
       "  78: '0810d42a-a881-4290-bc5d-8b655d5d2589',\n",
       "  79: 'c9d4360a-3fc9-42bc-8e17-82a3e4c3083a',\n",
       "  80: 'bcc1a80f-153f-40ea-bac6-2368748c4a9e',\n",
       "  81: 'd376dbef-7b96-45cd-b9ee-28f37fb671a0',\n",
       "  82: '295246a8-0f92-46f6-9771-793b83770d57',\n",
       "  83: '244d858e-febb-41d0-8dcb-236fd70b484f',\n",
       "  84: 'a879667b-8dcf-4526-b36b-8631a72b091c',\n",
       "  85: '153a2631-059d-4ef0-a07b-d2d44ee57afb',\n",
       "  86: '27c0802c-8b9a-473e-a675-5992ad09b61a',\n",
       "  87: '82a5d44d-0353-41e0-813d-6da6e6e23ea9',\n",
       "  88: '21db208d-11cb-4762-89b5-f600e4df7730',\n",
       "  89: '9f572a75-4a2d-439c-b62a-7ef30c8abb8f',\n",
       "  90: 'a1197f1d-6fd8-4d64-8f9e-a9798650afab',\n",
       "  91: '13079832-9b1f-4456-8a86-963643ac942d',\n",
       "  92: 'b3616fe8-41d3-4444-b732-be8cd4c25728',\n",
       "  93: '0a24c51f-6d42-4005-9247-1a92ef0d2f6e',\n",
       "  94: '2af71e12-6ab9-43b5-a20c-c7da26bf5847',\n",
       "  95: 'eb72d515-8b26-4c9e-aab3-0e8c4620b53b',\n",
       "  96: 'd822195c-35a9-4bc8-ac27-a6f5ea770f4b',\n",
       "  97: '70977c6c-9f2e-48d5-bc48-43a9f39f0a80',\n",
       "  98: '21623c7b-d66a-41ad-80d6-a952f8413398',\n",
       "  99: 'c70d5d57-44c2-4479-899f-a59d1fab0cb2',\n",
       "  100: 'ee251c25-76ec-4926-86eb-35ba82e2abd4',\n",
       "  101: '88d1bb70-a7cd-4f4f-adc8-e07dd6b805e7',\n",
       "  102: '7c3ead58-184c-4e82-991d-13e372522be2',\n",
       "  103: 'ce834992-095e-4481-a4ad-b1a3caf44fae',\n",
       "  104: 'd34d954f-5213-42c0-b483-b4e9969ff3fb',\n",
       "  105: '0776504f-67f5-4bad-8a84-a1e9006324e1',\n",
       "  106: 'dcd5074a-6d10-4e40-830a-13a728eed071',\n",
       "  107: 'd334d005-43aa-4d6a-b389-a01ed69b576e',\n",
       "  108: 'd248f1cb-ec23-4adc-bfc1-051f9b7bf451',\n",
       "  109: '5fa1b108-ec30-4baf-a85e-9978601304fc',\n",
       "  110: '595c5107-a493-4ec9-97a2-3af90c0cdbac',\n",
       "  111: 'bea3d3a4-e575-4a94-b8b5-774ebb01b69c',\n",
       "  112: 'aad27818-cd4f-481c-b584-f2fd2bb1814b',\n",
       "  113: 'bb910d14-9af3-4a68-8599-b1568b7bf276',\n",
       "  114: '041c2aea-888b-4c45-972a-ddb14e55b04f',\n",
       "  115: '2d0e46c8-31fc-4219-b872-0825277c8d72',\n",
       "  116: '187bec96-e1d2-496e-8d30-df8bbf7d03f9',\n",
       "  117: '461a8874-cb2b-4f1f-a260-4950bbbb54f4',\n",
       "  118: '7ecd67a4-eebf-4c73-a2b8-7045c145da94',\n",
       "  119: '628a5afa-2c06-4173-949f-d2f18574cbd7',\n",
       "  120: '84788d45-e0b3-4257-9bff-3061c047c447',\n",
       "  121: '87002257-e260-4040-8bbe-74988a89781a',\n",
       "  122: '4e6c7b4e-da48-4fde-98a0-ee06275748df',\n",
       "  123: 'e39c1e70-c11a-44a0-9138-9fc117d987f3',\n",
       "  124: '11809c37-0c4d-44b8-9711-fae560fe3b4a',\n",
       "  125: 'e0b51787-90f7-4dce-be3f-00390b532211',\n",
       "  126: 'c758f3b1-8599-49fd-bf70-7fd332d88cad',\n",
       "  127: '5a3e3ad0-7c95-4f2e-ba97-d7dbc62762d1',\n",
       "  128: 'da38d047-94ad-4b4c-b2cd-947cb07c4887',\n",
       "  129: 'd1aa4b65-5db1-46da-a755-bd3a27a114c1',\n",
       "  130: '25ed273c-0efb-45bb-8425-9dcb70867137',\n",
       "  131: 'eafe9d95-6828-4f85-a78f-cf7a62e3b330',\n",
       "  132: '1dfe56aa-e2c6-4ee8-b6cd-23f4e4ffcd8d',\n",
       "  133: '4a4110b4-8d25-4dc0-bc99-f347107641ca',\n",
       "  134: '22fe0e21-b681-485d-94d2-a005a97419b0',\n",
       "  135: '00a4de86-4fc6-459a-bdff-323775b26272',\n",
       "  136: '577263b6-fd16-485b-a2ce-4b32c38adbe4',\n",
       "  137: 'f4722078-9bd8-4a1c-aa32-1e63c472248b',\n",
       "  138: 'c953d42a-56e0-45c6-be6b-44cabb027e7d',\n",
       "  139: '77006db9-027c-4e71-904a-033fdc33175e',\n",
       "  140: '33a5f324-364e-406b-aff1-3e364aaa3b06',\n",
       "  141: '6e558fa0-1836-4872-81d9-03938d68bac5',\n",
       "  142: '358a7b58-ce4b-4821-aef2-cbf0f4ff39c2',\n",
       "  143: '3ebf820a-85ee-45c1-a942-e69e4e0d72ac',\n",
       "  144: '44ff19d6-9f9c-4bf3-ab3b-28f33c91284c',\n",
       "  145: 'ddcf27d0-78a0-4158-82f4-23f01a72a04f',\n",
       "  146: 'e0a6c423-1251-48a4-9f41-197147f81b48',\n",
       "  147: '6b898ec1-1d3a-4c7e-91cd-c3222c22ea04',\n",
       "  148: '70e13b75-e9b2-42cf-8ead-84d84e65af8d',\n",
       "  149: '32a4fba2-3270-4a2f-8224-def6cff9b898',\n",
       "  150: '06bec058-1f07-45fc-880c-828596fcdd03',\n",
       "  151: '39e0dd41-be25-4f43-981f-fc57dfdc0dd6',\n",
       "  152: '30979e51-80cc-4685-858e-9845bc5519a1',\n",
       "  153: 'd8aefc80-6002-4af0-b648-2591ff1470dd',\n",
       "  154: '7138fca5-45a6-4ff2-a178-6ad66ae5f942',\n",
       "  155: '14a99dd1-41c9-4939-ab21-76884f92eea6',\n",
       "  156: '395e33b6-61a9-474c-836f-5d3441f021be',\n",
       "  157: '786751af-29ee-4359-93a3-c28512e6bceb',\n",
       "  158: 'eed1e8ea-2388-4a40-bb24-71446ddbd58e',\n",
       "  159: 'feebce95-013b-43b4-b5c5-a3a820e4c4d7',\n",
       "  160: 'e7ce4d62-c8d9-493d-98a4-80e6f4bab97a',\n",
       "  161: 'a3ea5bf1-e34a-4e7e-829f-ca391dbcfb36',\n",
       "  162: 'a4466871-526f-4d10-ba68-5d69e3b9abb1',\n",
       "  163: '1f6c21a5-a3a2-4522-b39f-bea2e1f03766',\n",
       "  164: 'aeaac7e9-aca1-4afc-abbf-04755b2062a2',\n",
       "  165: '4bb794d0-f8d6-4238-bfc3-40d5b1e41783',\n",
       "  166: '75b84578-d9da-460a-af2f-63e540634409',\n",
       "  167: 'd40a009c-68d0-4ffb-a46b-50e40572cc33',\n",
       "  168: '0633b685-0265-4e9d-a87d-acfe254551c0',\n",
       "  169: 'e94b6fa3-d654-41a6-b927-93ded0432bb5',\n",
       "  170: '2a3bbb79-a400-4008-8702-33c54f42ace4',\n",
       "  171: '3277fe56-da01-4b6e-b5cc-672afeae4992',\n",
       "  172: 'dd92e72c-dea8-4f82-9b03-e15618da27c3',\n",
       "  173: 'ec92180b-c6c6-4475-82f6-ef9ddd4286ba',\n",
       "  174: 'f50a204a-4bea-4dda-bcb6-de4cbaab756f',\n",
       "  175: '909c0a5d-41ee-452e-89a1-bcf2d4ba50f6',\n",
       "  176: 'c415766e-3ca9-4acc-880d-5111f4662922',\n",
       "  177: '9e6efed3-67c2-4237-af10-98f6bd587425',\n",
       "  178: 'c84e4b54-a32a-4f0e-a909-a891635d8529',\n",
       "  179: 'e34f7d5c-f15f-48a3-a99a-83bc4e651d0d',\n",
       "  180: 'e1d1b6ec-5d80-4f4f-9cfd-f23bd50d933b',\n",
       "  181: '2242d746-9e99-48c2-ad37-54bc3c773243',\n",
       "  182: 'db747793-8955-4026-9ffe-9db76fcb2b6b',\n",
       "  183: '182b458d-b201-43aa-af50-09a0159cb58e',\n",
       "  184: 'bf0ee5eb-4e3c-44f2-9184-dc08ae3c280b',\n",
       "  185: '2744851f-c268-41bc-8f5e-98a395c0f6e8',\n",
       "  186: 'd725bb11-7262-476e-a6be-8841ff06f654',\n",
       "  187: '3d46a990-2713-461a-84f6-ff454e7f31fd',\n",
       "  188: 'a3815e63-ba82-41aa-926f-71f416bc13bd',\n",
       "  189: 'c5f68e2f-9ce9-4edf-952e-2e1e832182d9',\n",
       "  190: '8ead4cf7-eb6b-44eb-97ae-e889784b4a48',\n",
       "  191: '8a231da5-e17a-4ecd-a77c-ca1ba5ca985d',\n",
       "  192: '7d506a6d-0761-4cc3-b999-bbb98a956799',\n",
       "  193: 'ccc6b128-2fca-413b-96b9-b3689f10eeb5',\n",
       "  194: '8f45da6c-69e1-4261-bf07-1723bb466dd9',\n",
       "  195: '8b0e3424-c90b-4c47-840e-c5839d9ec229',\n",
       "  196: 'fb38d925-e120-4220-948b-70cfdfc44152',\n",
       "  197: '63e5bd65-e88d-430c-b3bd-071a5e596bc7',\n",
       "  198: '515c33d2-9c84-409f-874e-216ba21c55a4',\n",
       "  199: 'f9bba3b7-b529-4cfb-a86c-59636570807b',\n",
       "  200: '704fcc38-4d93-4ce1-9cc6-a60739e69d35',\n",
       "  201: '6ee740fa-dd28-4a8b-8fd4-fb4070679b7d',\n",
       "  202: '954bc329-070d-46f2-ad9d-fedc9beb0575',\n",
       "  203: '8127ae5c-7a54-41d5-b855-67607d9c31f0',\n",
       "  204: 'cffa0bf8-e97e-4423-be3c-bede3ac1ed05',\n",
       "  205: '585159cf-8ccb-4076-973c-e3b32eeee78f',\n",
       "  206: '7a000774-ff92-41d8-8e84-bd83c281e1ae',\n",
       "  207: '5e161af4-1784-486e-a287-d5a615dccf5c',\n",
       "  208: '4a9d6d18-a3af-441c-886d-695d9137cdd8',\n",
       "  209: '0f0eab49-194c-4250-a0ed-ad0a5bff32b3',\n",
       "  210: 'f9fe55ff-38f9-48da-9ee9-5515186e96c0',\n",
       "  211: '742955d8-5068-4521-af6b-f6ae0e78141a',\n",
       "  212: '2cc380c5-e0f5-47ba-a829-2b1c2964c831',\n",
       "  213: 'edad9107-7aba-4c12-a930-cbf10e73d282',\n",
       "  214: '6dbe8d0a-c47c-4e92-9065-579cef639fd7',\n",
       "  215: '19a4414f-2f6e-47ec-8797-01e2c4ab3f7e',\n",
       "  216: 'b6bc22ce-c44f-499b-9878-ebac9a5d6ed7',\n",
       "  217: '066cff04-e472-4ca6-83b5-558b2aeef413',\n",
       "  218: '09b30e57-3c27-49b6-b3c0-801ddca4446b',\n",
       "  219: '6a35fc79-89ef-416e-82a9-865c39941fa4',\n",
       "  220: '398d2bbc-234e-4a40-a194-474cf44a099f',\n",
       "  221: '6ced0154-9b94-4e39-8713-b35900fb5c3c',\n",
       "  222: '90fc7365-bfff-43a3-9f50-81d29c6993b0',\n",
       "  223: '5ccc7b88-d04c-47c8-9a19-60e8f034b992',\n",
       "  224: '46e04e87-b7bf-489f-b966-60ad0d45d4b2',\n",
       "  225: '9eeb5f3d-da5a-4aaa-8936-d7d027784ccd',\n",
       "  226: '87c0b68e-dcf3-445b-9121-3d1d3852cbcb',\n",
       "  227: 'a25aa4ff-2f26-4db5-b940-f6aaa6e086dc',\n",
       "  228: 'a5607256-2a70-424a-bef5-f001d7656479',\n",
       "  229: 'e9c44e09-5ba5-459f-b19b-8cc09150633a',\n",
       "  230: 'e4d823a9-28ca-46ba-8e14-2fedd0292d96',\n",
       "  231: 'd8e35515-9d2f-4e46-b95f-1a07db3c0c43',\n",
       "  232: '98b2a998-3f50-43c7-b9a1-a4f48742cb48',\n",
       "  233: '1fc407cc-eac2-49cf-9a0f-87f73188f502',\n",
       "  234: '6267d23f-f4db-457c-89bf-4c194e60b4f7',\n",
       "  235: '3a925ec2-694b-4db4-89af-969a0ad1a271',\n",
       "  236: '3fb31e47-49a5-48c2-8478-256d9c956b5d',\n",
       "  237: 'a5346f24-2b6e-4a5c-a7e1-6e51ab212622',\n",
       "  238: '2caed1ce-4478-4a22-af35-9b5625047510',\n",
       "  239: '50417cf0-65f5-4dea-9813-41a805c07a19',\n",
       "  240: '919d6805-124d-47a0-bd56-05d9434f9246',\n",
       "  241: '3349af9a-34da-44d4-8d24-2eac0f457d09',\n",
       "  242: '587f1475-1ac6-4dbd-b6be-2b41b1491013',\n",
       "  243: '231b2c20-5904-463f-8544-b29113cd1ee7',\n",
       "  244: 'b50463ab-0cd7-41fb-80f3-f031d02e541a',\n",
       "  245: '53359c91-baff-4178-a345-b1b41ccd4380',\n",
       "  246: '2f76dd79-dcae-4f6f-8b7f-5a2555c1b8fa',\n",
       "  247: '84f62509-3944-403c-be69-337b98a04c88',\n",
       "  248: '7c7ac45a-4288-43ad-8c38-de858367400b',\n",
       "  249: 'cca2cc42-7160-4e46-a233-5f328e68a25f',\n",
       "  250: '603196dc-c5a0-46c6-bc72-22098abde231',\n",
       "  251: '83bdfc41-28a0-4d01-a99a-7201877c5e20',\n",
       "  252: '31f1b926-7ee6-43db-927f-d71ea39d5f60',\n",
       "  253: '78f64498-b784-4bf1-9542-95268f2259b1',\n",
       "  254: '831b1490-7c88-42f6-8df8-35a06b3ca019',\n",
       "  255: '1a6225e5-9145-4058-a5bf-eaf8425bf7db',\n",
       "  256: '2f777c1f-780a-4102-b6db-b219e314701b',\n",
       "  257: 'f6088609-b96f-4f8d-98ac-44f4cfd024df',\n",
       "  258: '9840d814-81e6-44c8-b62c-be4ea2b35897',\n",
       "  259: '866eab76-1d0e-448d-b41c-bb642b0cf127',\n",
       "  260: '5966a0fc-c7e8-4100-a86d-c1592b138549',\n",
       "  261: '2640e55d-5556-4863-85a0-1de411a37012',\n",
       "  262: '84254ab1-091d-414b-8863-183610dbb992',\n",
       "  263: 'bee2ea52-ff8d-4154-b6eb-6f381f73e5a8',\n",
       "  264: '5d61c57d-887d-4daf-9122-5e4e7c992cc4',\n",
       "  265: '2d473ce2-d0b5-4bac-89e3-a3146345a21e',\n",
       "  266: '3a7a4364-1fd3-485a-b3ec-7d120a91bcaf',\n",
       "  267: 'd4e8bf37-a2dc-41ca-ad42-7eb688d7ba8d',\n",
       "  268: 'b37cb24c-d506-4612-ba15-c722f73ec0a1',\n",
       "  269: '72ba1223-4479-4b96-a074-f4461f7f9b7a',\n",
       "  270: '5c08456e-865a-4312-b613-6cf838bd7767',\n",
       "  271: 'd604aaec-c296-4c45-9f81-42e2998272a9',\n",
       "  272: '9d4df71b-a1dd-4c4a-92c6-3f8efecc8906',\n",
       "  273: 'e46a87c0-56f0-4d6e-9fa5-c85ca72ff77c',\n",
       "  274: '898e582e-3887-40af-a42b-42af930ed84a',\n",
       "  275: '9b19cdaf-abf6-445a-b2dd-867c16dba69a',\n",
       "  276: '61d78871-433a-4677-98ed-d5f5b7c1f68a',\n",
       "  277: '91f25961-365b-4119-8cc3-08561965d98f',\n",
       "  278: '256b9ea1-7680-4d24-902a-1dddee5bf5d8',\n",
       "  279: '84587383-d25a-4c74-a5d5-639741433ec7',\n",
       "  280: 'c1222a9e-41a0-4a11-823f-7a87dd4279dd',\n",
       "  281: '62562772-87c6-46c2-9312-87310966386d',\n",
       "  282: '07f60460-f7f7-4e0d-b9dc-91850e3c00f8',\n",
       "  283: '77688b74-d85a-489e-80eb-1b18a46470c0',\n",
       "  284: 'e5e6abf5-2a65-4c45-83ba-f63656c1f17a',\n",
       "  285: 'f25caa22-18a3-499e-9971-2e335cad32f2',\n",
       "  286: '4efe85aa-e1d6-4d39-a20e-31c5a3267b57',\n",
       "  287: 'd15bb069-5cb9-4997-a45d-ecce69fd0dd7',\n",
       "  288: '025f5951-631b-4a23-9de4-e9774b2d25b0',\n",
       "  289: 'a58f7e23-254c-425a-b0e1-83ea6f3bc68b',\n",
       "  290: '4740fc15-9005-4148-b63a-133fd7a09471',\n",
       "  291: 'b8392d74-9b2b-4398-9e40-b071ae34bea9',\n",
       "  292: 'b1b9ee83-0161-4602-b930-b25b49057d0f'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(r'C:\\Users\\KIIT\\Dropbox\\My PC (BT1906126)\\Documents\\projects\\Code\\buildspace\\RAG\\genieFile\\saved_embeddings\\index.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Contact Sancharika Debnath 9477230267 (Mobile) sancharikadebnath@gmail.com Passionate Data Scientist || Machine Learning|| AI || Innovator in Emerging Technologies www.linkedin.com/in/sancharika- Kolkata, West Bengal, India debnath (LinkedIn) huggingface.co/sancharikadebnath (Portfolio) Summary github.com/sancharika/ (Portfolio) Welcome to my professional journey! I'm Sancharika Debnath, a Top Skills dynamic Data Scientist driven by a fervent enthusiasm for leveraging cutting-edge technology to craft innovative solutions. With a solid RAG Model foundation in data science and backend development, I specialize in Vector Databases translating complex data into actionable insights and robust systems. Prompt Engineering Certifications My career has been an exhilarating exploration of possibilities, from developing agile event systems integrated with facial recognition Machine Learning for seamless attendance management to architecting custom APIs Problem Solving (Intermediate) for large-scale data retrieval. At Giggr Technology, I spearheaded Introduction to C++ GAIT Online Program IT the development of a transformative event system, achieving an Professional - Silver impressive accuracy rate of 87.4% through a blend of OpenCV, AWS Machine Learning Engineer YOLO, and Deep-Face technologies. Nanodegree In my tenure at Leapon, I honed my backend development skills, Publications crafting tailored solutions using Python, Django, and AWS to Hyperspectral Image Compression optimize website performance and enhance user experiences. This using Modified Convolutional Autoencoder experience instilled in me the importance of precision and scalability in every project I undertake. As a Data Science Intern at Maersk Global Service Centres, I delved into predictive analytics and optimization, devising algorithms to forecast container turn times and enhance logistical efficiency. My passion for exploring the intersections of data and technology led me to HighRadius Corporation, where I pioneered a regression invoice prediction system, leveraging machine learning models for streamlined financial operations. Outside of the corporate realm, I'm an avid contributor to the tech community, with publications in esteemed journals such as the International Journal of Computational Intelligence Systems. My recent research on Hyperspectral Image Compression Page 1 of 4and Classification, achieving a remarkable accuracy of 99.8%, underscores my dedication to pushing the boundaries of innovation. I thrive in collaborative environments where creativity meets technical prowess, and I'm eager to connect with like-minded professionals and organizations committed to driving meaningful change through data-driven insights. Let's embark on a journey of innovation together! Experience Data Scientist February 2024 - Present (4 months) Giggr - The Future of Work Data Scientist July 2023 - February 2024 (8 months) Bengaluru, Karnataka, India • Responsibility: Integrated experience in artificial intelligence, data science and graph database architecture to deliver comprehensive solutions – Engineered an innovative data-driven event system integrating facial recognition for attendance tracking and object detection for gamification purposes. (Accuracy: 87.4) – Integrated GPS functionality to facilitate user navigation to the event venue, enhancing overall user experience and convenience. – Guided the team in developing a Neo4j architecture, quickly acquiring intermediate proficiency. Collaboratively integrated it into the project ecosystem, enhancing data management and analytics capabilities while teamwork. – Crafted and worked independently to create custom public API from scratch, prioritizing data security while utilizing S3 and Elasticsearch to efficiently search through a dataset of over 1.3 million education institutes across India. – Designed and implemented a quiz chatbot for digital maturity evaluation using Dialogflow, featuring a sophisticated scoring system and seamless Firebase integration, enriching user interaction and data functionality. Leapon Back End Developer February 2023 - June 2023 (5 months) Remote Page 2 of 4• Responsibility: Constructed and developed the Backend architecture for the entire website personalised for 50+ advisor connectivity. – Developed REST APIs to facilitate seamless communication between the frontend and backend systems and integrated A/B testing frameworks to analyze user interactions and optimize feature performance. – Utilized CI/CD pipelines to streamline the development process, ensuring rapid and reliable deployment of new features and updates, thereby enhancing advisor networking by up to 60% with effective decision support. A.P. Moller - Maersk Data Science Intern July 2022 - February 2023 (8 months) Bengaluru, Karnataka, India Worked on various data science related and web development related real life projects. • Created an end-to-end web application for pre-booking seats in office premises using springboot, next.js and internal UI developer, Anchor UI. • Clustering of ports based on predominant features using different clustering techniques ( Best Model : Gaussian Mixture ). • Prediction of container turn time considering time series effects of the data. • Prediction of change in attachment ratio percentage using various AutoML ( Best Model : FLAML). HighRadius Data Sceince Intern January 2022 - April 2022 (4 months) Bhubaneswar, Odisha, India Developed an Automation invoice prediction system. • Using machine learning algorithms (Best Model: XGBoost) for prediction of invoice clearance date. • JDBC, and React JS was used on a real world transaction database for an interactive web page. (Accuracy: 76.15) The Sparks Foundation Data Science & Business Analytics Intern July 2021 - August 2021 (2 months) Page 3 of 4• Prediction of student performance Using Supervised Machine Learning Algorithm • Achieved accuracy rate of 95.5 Ativeer Tech Data Science Intern June 2021 - July 2021 (2 months) • Product appending in the website back-end • Used WordPress and Wix to represent product details for more than 150+ products Education Kalinga Institute of Industrial Technology, Bhubaneswar 4th, year, Information Technology · (July 2019 - July 2023) Kendriya Vidyalaya · (2007 - 2019) Page 4 of 4\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Contact Sancharika Debnath 9477230267 (Mobile) sancharikadebnath@gmail.com Passionate Data Scientist || Machine Learning|| AI || Innovator in Emerging Technologies www.linkedin.com/in/sancharika- Kolkata, West Bengal, India debnath (LinkedIn) huggingface.co/sancharikadebnath (Portfolio) Summary github.com/sancharika/ (Portfolio) Welcome to my professional journey! I'm Sancharika Debnath, a Top Skills dynamic Data Scientist driven by a fervent enthusiasm for leveraging cutting-edge technology to craft innovative solutions. With a solid RAG Model foundation in data science and backend development, I specialize in Vector Databases translating complex data into actionable insights and robust systems. Prompt Engineering Certifications My career has been an exhilarating exploration of possibilities, from developing agile event systems integrated with facial recognition Machine Learning for seamless attendance management to architecting custom APIs Problem Solving (Intermediate) for large-scale data retrieval. At Giggr Technology, I spearheaded Introduction to C++ GAIT Online Program IT the development of a transformative event system, achieving an Professional - Silver impressive accuracy rate of 87.4% through a blend of OpenCV, AWS Machine Learning Engineer YOLO, and Deep-Face technologies. Nanodegree In my tenure at Leapon, I honed my backend development skills, Publications crafting tailored solutions using Python, Django, and AWS to Hyperspectral Image Compression optimize website performance and enhance user experiences. This using Modified Convolutional Autoencoder experience instilled in me the importance of precision and scalability in every project I undertake. As a Data Science Intern at Maersk Global Service Centres, I delved into predictive analytics and optimization, devising algorithms to forecast container turn times and enhance logistical efficiency. My passion for exploring the intersections of data and technology led me to HighRadius Corporation, where I pioneered a regression invoice prediction system, leveraging machine learning models for streamlined financial operations. Outside of the corporate realm, I'm an avid contributor to the tech community, with publications in esteemed journals such as the International Journal of Computational Intelligence Systems. My recent research on Hyperspectral Image Compression Page 1 of 4and Classification, achieving a remarkable accuracy of 99.8%, underscores my dedication to pushing the boundaries of innovation. I thrive in collaborative environments where creativity meets technical prowess, and I'm eager to connect with like-minded professionals and organizations committed to driving meaningful change through data-driven insights. Let's embark on a journey of innovation together! Experience Data Scientist February 2024 - Present (4 months) Giggr - The Future of Work Data Scientist July 2023 - February 2024 (8 months) Bengaluru, Karnataka, India • Responsibility: Integrated experience in artificial intelligence, data science and graph database architecture to deliver comprehensive solutions – Engineered an innovative data-driven event system integrating facial recognition for attendance tracking and object detection for gamification purposes. (Accuracy: 87.4) – Integrated GPS functionality to facilitate user navigation to the event venue, enhancing overall user experience and convenience. – Guided the team in developing a Neo4j architecture, quickly acquiring intermediate proficiency. Collaboratively integrated it into the project ecosystem, enhancing data management and analytics capabilities while teamwork. – Crafted and worked independently to create custom public API from scratch, prioritizing data security while utilizing S3 and Elasticsearch to efficiently search through a dataset of over 1.3 million education institutes across India. – Designed and implemented a quiz chatbot for digital maturity evaluation using Dialogflow, featuring a sophisticated scoring system and seamless Firebase integration, enriching user interaction and data functionality. Leapon Back End Developer February 2023 - June 2023 (5 months) Remote Page 2 of 4• Responsibility: Constructed and developed the Backend architecture for the entire website personalised for 50+ advisor connectivity. – Developed REST APIs to facilitate seamless communication between the frontend and backend systems and integrated A/B testing frameworks to analyze user interactions and optimize feature performance. – Utilized CI/CD pipelines to streamline the development process, ensuring rapid and reliable deployment of new features and updates, thereby enhancing advisor networking by up to 60% with effective decision support. A.P. Moller - Maersk Data Science Intern July 2022 - February 2023 (8 months) Bengaluru, Karnataka, India Worked on various data science related and web development related real life projects. • Created an end-to-end web application for pre-booking seats in office premises using springboot, next.js and internal UI developer, Anchor UI. • Clustering of ports based on predominant features using different clustering techniques ( Best Model : Gaussian Mixture ). • Prediction of container turn time considering time series effects of the data. • Prediction of change in attachment ratio percentage using various AutoML ( Best Model : FLAML). HighRadius Data Sceince Intern January 2022 - April 2022 (4 months) Bhubaneswar, Odisha, India Developed an Automation invoice prediction system. • Using machine learning algorithms (Best Model: XGBoost) for prediction of invoice clearance date. • JDBC, and React JS was used on a real world transaction database for an interactive web page. (Accuracy: 76.15) The Sparks Foundation Data Science & Business Analytics Intern July 2021 - August 2021 (2 months) Page 3 of 4• Prediction of student performance Using Supervised Machine Learning Algorithm • Achieved accuracy rate of 95.5 Ativeer Tech Data Science Intern June 2021 - July 2021 (2 months) • Product appending in the website back-end • Used WordPress and Wix to represent product details for more than 150+ products Education Kalinga Institute of Industrial Technology, Bhubaneswar 4th, year, Information Technology · (July 2019 - July 2023) Kendriya Vidyalaya · (2007 - 2019) Page 4 of 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"FIREWORKS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_fireworks import ChatFireworks\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI , OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "load_dotenv()\n",
    "model = ChatFireworks(model=\"accounts/fireworks/models/firefunction-v1\", fireworks_api_key= os.getenv(\"FIREWORKS_API_KEY\"))\n",
    "\n",
    "def add_graph(text, model):\n",
    "    llm_transformer = LLMGraphTransformer(llm=model)\n",
    "    documents = [Document(page_content=text)]\n",
    "    graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "    print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "    print(f\"Relationships:{graph_documents[0].relationships}\")\n",
    "    graph = Neo4jGraph()\n",
    "    graph.add_graph_documents(\n",
    "    graph_documents, \n",
    "    baseEntityLabel=True, \n",
    "    include_source=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "# Function to \n",
    "def delete_db():\n",
    "    # # delte vector db\n",
    "    # file_path = 'saved_embeddings'\n",
    "    # # Check if the file exists\n",
    "    # if os.path.exists(file_path+'\\index.faiss'):\n",
    "    #        # Delete the file\n",
    "    #     os.remove(file_path+'\\index.faiss')\n",
    "    # if os.path.exists(file_path+'\\index.pkl'):\n",
    "    #    # Delete the file\n",
    "    #     os.remove(file_path+'\\index.pkl')\n",
    "\n",
    "    # delete the graph\n",
    "    uri = os.getenv(\"NEO4J_URI\") \n",
    "    user = os.getenv(\"NEO4J_USERNAME\")\n",
    "    password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    with driver.session() as session:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    driver.close()\n",
    "    print(\"Graph deleted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph deleted successfully\n"
     ]
    }
   ],
   "source": [
    "delete_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"\n",
    "THE\n",
    "ALCHEMISTPAULO COELHO\n",
    "TRANSLATED BY ALAN R. CLARKEContents\n",
    "INTRODUCTION\n",
    "I remember receiving a letter from the\n",
    "American publisher Harper Collins…\n",
    "PROLOGUE\n",
    "The alchemist picked up a book that someone\n",
    "in the…\n",
    "O\n",
    "NE\n",
    "The boy’s name was Santiago. Dusk was\n",
    "falling as the…T\n",
    "WO\n",
    "The boy had been working for the crystal\n",
    "merchant for…\n",
    "EPILOGUE\n",
    "The boy reached the small, abandoned\n",
    "church just as night…\n",
    "ABOUT THE AUTHOR\n",
    "INTERNATIONAL ACCLAIM\n",
    "BOOKS BY PAULO COELHOCREDITS\n",
    "COVER\n",
    "COPYRIGHT\n",
    "ABOUT THE PUBLISHERTEN YEARS ON\n",
    "I A publisher Harper\n",
    "REMEMBER RECEIVING A LETTER FROM THE MERICAN\n",
    "Collins that said that: “reading The Alchemist was like getting up at\n",
    "dawn and seeing the sun rise while the rest of the world still slept.” I\n",
    "went outside, looked up at the sky, and thought to myself: “So, the\n",
    "book is going to be published in English!” At the time, I was\n",
    "struggling to establish myself as a writer and to follow my path\n",
    "despite all the voices telling me it was impossible.\n",
    "And little by little, my dream was becoming reality. Ten, a\n",
    "hundred, a thousand, a million copies sold in America. One day, a\n",
    "Brazilian journalist phoned to say that President Clinton had been\n",
    "photographed reading the book. Some time later, when I was in\n",
    "Turkey, I opened the magazine Vanity Fair and there was Julia\n",
    "Roberts declaring that she adored the book. Walking alone down a\n",
    "street in Miami, I heard a girl telling her mother: “You must read\n",
    "The Alchemist!”\n",
    "The book has been translated into fifty-six languages, has sold\n",
    "more than twenty million copies, and people are beginning to ask:\n",
    "What’s the secret behind such a huge success?\n",
    "The only honest response is: I don’t know. All I know is that, like\n",
    "Santiago the shepherd boy, we all need to be aware of our personal\n",
    "calling. What is a personal calling? It is God’s blessing, it is the path\n",
    "that God chose for you here on Earth. Whenever we do something\n",
    "that fills us with enthusiasm, we are following our legend. However,\n",
    "we don’t all have the courage to confront our own dream.Why?\n",
    "There are four obstacles. First: we are told from childhood\n",
    "onward that everything we want to do is impossible. We grow up\n",
    "with this idea, and as the years accumulate, so too do the layers of\n",
    "prejudice, fear, and guilt. There comes a time when our personal\n",
    "calling is so deeply buried in our soul as to be invisible. But it’s still\n",
    "there.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_fireworks import ChatFireworks\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# model = ChatFireworks(model=\"accounts/fireworks/models/firefunction-v1\", fireworks_api_key= os.getenv(\"FIREWORKS_API_KEY\"))\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=\"gemma2-9b-It\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Santiago', type='Person'), Node(id='The Alchemist', type='Book'), Node(id='Harper Collins', type='Publisher'), Node(id='Julia Roberts', type='Person'), Node(id='Brazilian Journalist', type='Person'), Node(id='President Clinton', type='Person'), Node(id='Girl', type='Person')]\n",
      "Relationships:[Relationship(source=Node(id='Santiago', type='Person'), target=Node(id='The Alchemist', type='Book'), type='READ'), Relationship(source=Node(id='Harper Collins', type='Publisher'), target=Node(id='The Alchemist', type='Book'), type='PUBLISH'), Relationship(source=Node(id='Julia Roberts', type='Person'), target=Node(id='The Alchemist', type='Book'), type='ADORE'), Relationship(source=Node(id='Brazilian Journalist', type='Person'), target=Node(id='The Alchemist', type='Book'), type='READ'), Relationship(source=Node(id='President Clinton', type='Person'), target=Node(id='The Alchemist', type='Book'), type='READ'), Relationship(source=Node(id='Girl', type='Person'), target=Node(id='The Alchemist', type='Book'), type='RECOMMEND')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI , OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "# llm = ChatGoogleGenerativeAI( model= \"gemini-1.5-flash-latest\")\n",
    "llm_transformer = LLMGraphTransformer(llm=model)\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nTHE\\nALCHEMISTPAULO COELHO\\nTRANSLATED BY ALAN R. CLARKEContents\\nINTRODUCTION\\nI remember receiving a letter from the\\nAmerican publisher Harper Collins…\\nPROLOGUE\\nThe alchemist picked up a book that someone\\nin the…\\nO\\nNE\\nThe boy’s name was Santiago. Dusk was\\nfalling as the…T\\nWO\\nThe boy had been working for the crystal\\nmerchant for…\\nEPILOGUE\\nThe boy reached the small, abandoned\\nchurch just as night…\\nABOUT THE AUTHOR\\nINTERNATIONAL ACCLAIM\\nBOOKS BY PAULO COELHOCREDITS\\nCOVER\\nCOPYRIGHT\\nABOUT THE PUBLISHERTEN YEARS ON\\nI A publisher Harper\\nREMEMBER RECEIVING A LETTER FROM THE MERICAN\\nCollins that said that: “reading The Alchemist was like getting up at\\ndawn and seeing the sun rise while the rest of the world still slept.” I\\nwent outside, looked up at the sky, and thought to myself: “So, the\\nbook is going to be published in English!” At the time, I was\\nstruggling to establish myself as a writer and to follow my path\\ndespite all the voices telling me it was impossible.\\nAnd little by little, my dream was becoming reality. Ten, a\\nhundred, a thousand, a million copies sold in America. One day, a\\nBrazilian journalist phoned to say that President Clinton had been\\nphotographed reading the book. Some time later, when I was in\\nTurkey, I opened the magazine Vanity Fair and there was Julia\\nRoberts declaring that she adored the book. Walking alone down a\\nstreet in Miami, I heard a girl telling her mother: “You must read\\nThe Alchemist!”\\nThe book has been translated into fifty-six languages, has sold\\nmore than twenty million copies, and people are beginning to ask:\\nWhat’s the secret behind such a huge success?\\nThe only honest response is: I don’t know. All I know is that, like\\nSantiago the shepherd boy, we all need to be aware of our personal\\ncalling. What is a personal calling? It is God’s blessing, it is the path\\nthat God chose for you here on Earth. Whenever we do something\\nthat fills us with enthusiasm, we are following our legend. However,\\nwe don’t all have the courage to confront our own dream.Why?\\nThere are four obstacles. First: we are told from childhood\\nonward that everything we want to do is impossible. We grow up\\nwith this idea, and as the years accumulate, so too do the layers of\\nprejudice, fear, and guilt. There comes a time when our personal\\ncalling is so deeply buried in our soul as to be invisible. But it’s still\\nthere.\\n']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.page_content for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "graph.add_graph_documents(\n",
    "  graph_documents, \n",
    "  baseEntityLabel=True, \n",
    "  include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contact Sancharika Debnath 9477230267 (Mobile) sancharikadebnath@gmail.com Passionate Data Scientist'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.neo4j_vector.Neo4jVector at 0x16a1655e390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings\n",
    "vectorestore = Neo4jVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=documents,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.neo4j_vector.Neo4jVector at 0x16b5ce5f8f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neo4jVector(\n",
    "    embeddings,\n",
    "    pre_delete_collection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "text: International Journal of Computer Information Systems and Industrial Management Applications.\n",
      "ISSN 2150-7988 Volume 15 (2023) pp. 396-407\n",
      "© MIR Labs, www.mirlabs.net/ijcisim/index.html\n",
      "Received: 14 January 2022; Accepted: 19 May, 2023; Published: 23 June, 2023\n",
      "Hyperspectral Image Compression using Modified\n",
      "Convolutional Autoencoder\n",
      "Satvik Agrawal1, Sancharika Debnath1, Santwana Sagnika1,*, Saurabh Bilgaiyan1, Saksham Gupta2\n",
      "1 School of Computer Engineering, Kalinga Institute of Industrial\n",
      "Technology Deemed to be University, India\n",
      "satvik.agrawal2001@gmail.com, sancharikadebnath@gmail.com, santwana.sagnika@gmail.com, saurabhbilgaiyan01@gmail.com\n",
      "2 Computer Science Engineering Department, Chandigarh\n",
      "College of Engineering and Technology, India\n",
      "dev.sakshamgupta@gmail.com\n",
      "Abstract: Spectral imaging is a type of multi band imaging materials with various properties. Agriculture, environmental\n",
      "technique of the electromagnetic spectrum, used for gathering monitoring, weather prediction, military, food industry,\n",
      "and analysis of information. Hyperspectral imaging is a medicinal, and forensic research are some examples of\n",
      "technique that collects spectral information from a broad hyperspectral remote sensing applications.\n",
      "spectrum of wavelengths for the same spatial area of each pixel.\n",
      "Hyperspectral images store a load of data which can be\n",
      "Due to its multiple bands, and spectral and spatial redundancy,\n",
      "processed to obtain a large spectrum of meaningful\n",
      "the image size is immense. Processing these images requires an\n",
      "information. Storing huge spectral dimensionality of multiple\n",
      "enormous amount of memory. Our paper proposes a lossy\n",
      "spectral channels requires enormous memory. A single HIS\n",
      "technique to encode and compress the hyperspectral images by\n",
      "the help of deep convolutional networks, autoencoders and dataset can have a size of hundreds of megabytes (MBs), since\n",
      "attention layers. The encoder uses convolutional and max each pixel holds 16-bit or 12-bit information, the range of the\n",
      "pooling layers, connected to a singular attention layer to encode pixel numbers can vary from few hundreds to millions, and as\n",
      "the data, and the decoder has a single dense layer preceding high as 22 bands can be the band numbers. [2]. For example,\n",
      "transpose convolutional and upsampling layers to decode the the dataset of calibrated images of standard Consultative\n",
      "coded data back into the hyperspectral images. The method is\n",
      "Committee for Space Data Systems (CCSDS) [3] has 224\n",
      "tested on different images taken by the Airborne Visible/\n",
      "total spectral bands, 677 × 512 counts of pixels per band , and\n",
      "Infrared Imaging Spectrometer (AVIRIS), Reflective Optics\n",
      "16-bits of information is stored in each pixel. Thus, 677 × 512\n",
      "System Imaging Spectrometer (ROSIS), and NASA EO1 satellite.\n",
      "× 224 × 16 bits = 148 MB is the size of this standardized\n",
      "The method achieves superior results than existing work by up\n",
      "to a 5% increase in the PSNR and up to 200 times increase in the image [2].\n",
      "compression ratio. The analysis of enormous HSI while keeping the necessary\n",
      "valuable information is a major issue. It is a primary problem\n",
      "Keywords: Hyperspectral image processing, autoencoder, image for compression algorithms because data compression is\n",
      "compression, deep learning, neural network. performed to decrease data redundancy [1]. High data\n",
      "redundancy usually equates to high compression ratios, while\n",
      "I. Introduction poor redundancy equates to low compression ratios. In\n",
      "multi-spectral images such as HSI, there are four types of\n",
      "Spectral imaging utilizes multiple bands over the\n",
      "redundancy:\n",
      "electromagnetic spectrum. It denotes a group of analytic\n",
      "I) Statistical redundancy - analysis of the probability of\n",
      "techniques using multiple bands from the spectrum, and\n",
      "symbols. The methods used to analyse the probability of\n",
      "collects both spectroscopic information and imaging\n",
      "symbols are called entropy coding.\n",
      "information at the same time. The image data from few broad\n",
      "II) Spatial redundancy - intraband correlation assumes that\n",
      "wavelengths (approx. 3 to 15 bands) are captured via\n",
      "the pixel information could be partially obtained by\n",
      "Multispectral remote sensors. Comparatively, the image data\n",
      "neighboring pixels. It can be removed via transformation.\n",
      "from the numerous spectral band covering an extended range\n",
      "of wavelength from 400 to 2500nm is simultaneously III) Spectral redundancy - or interband correlation, based\n",
      "collected via hyperspectral (HS) remote sensors [1]. on the high correlation existing between neighboring bands in\n",
      "Hyperspectral imaging is a technique based on spectroscopy. hyperspectral images. It can be removed by spatial\n",
      "Multiple bands of image data are gathered at multiple decorrelation.\n",
      "wavelengths for each spatial area. This gathered data creates a IV) Visual redundancy - driven by the detail that human\n",
      "hyperspectral cube, two of its dimensions signify spatial eyes are not overly sensitive to high frequencies, data\n",
      "extent of the location and the third stands for spectral content. quantization is used to achieve compression based on visual\n",
      "The spectral signature is the outcome of molecule absorption redundancy. The utilization of interband or intraband\n",
      "and particle scattering, and it allows for the differentiation of correlations allows compression techniques to be divided into\n",
      "MIR Labs, USAHyperspectral Image Compression using Modified Convolutional Autoencoder 397\n",
      "2D and 3D methods. 2D image compression methods multiple transformations to enable compaction property. The\n",
      "typically employ intraband and interband correlations model can eliminate the need for encoding super pixel maps\n",
      "individually, while 3D techniques use both inter-and with the aid of an ordering scheme of sparse coefficients. In\n",
      "intraband correlations together [4]. addition, MSSASR preserved anomaly regions better than\n",
      "Hyperspectral images are merged with many recent other algorithms. Barrios et al. (2020) [7] proposed a\n",
      "technologies for advancement in this domain. In the past few hardware implementation for lossy Multispectral and HSI\n",
      "years, research in this discipline has increased with the aid of compressors for onboard space missions. It extends the\n",
      "diverse kinds of neural networks and autoencoders. A neural CCSDS 123.0-B-1 lossless standard. The High-Level\n",
      "network is a basically sequence of calculating units that Synthesis (HLS) techniques are used for algorithm\n",
      "endeavor to acknowledge inherent relationships among a\n",
      "implementation to increase productivity of design by raising\n",
      "group of data through a process that imitates the operation of\n",
      "the abstract level. The model is deployed onto ARTICo, and\n",
      "the human brain, Therefore, neural networks are interlinked\n",
      "Xilinx Zynq Ultra Scale +Field-Programmable Gate Array\n",
      "systems of neurons, either organic or artificial [5]. An\n",
      "(FPGA)-based MPSoC is used to test the compression\n",
      "autoencoder is a model implementing unsupervised deep\n",
      "solution. It gives improved results compared to the state of the\n",
      "learning that trains the network to disregard signal noise and\n",
      "art algorithms in terms of both computational cost and\n",
      "generate efficient data representations, known as encoding.\n",
      "compression quality.\n",
      "The primary goal of an autoencoder is to convert\n",
      "In the field of lossless compression, Zhu et al. (2020) [8]\n",
      "high-dimensional space data to lower dimensions.\n",
      "presented an improved Conventional least square (CRLS)\n",
      "The paper proposes a modified lossy deep convolutional\n",
      "with adaptive predictor selection and adaptive band selection\n",
      "neural network autoencoder framework that includes an\n",
      "attention layer to encode and later decode hyperspectral image (CRLS-APS-ABS). It uses several strategies for improvement.\n",
      "data. The proposed method uses convolutional layers and max In order to enhance the correlation among the reference bands\n",
      "pooling layers for the encoder along with an attention layer, and prediction bands, an adaptive band selection strategy is\n",
      "and convolution transpose layers in the decoder. The task of utilized. To attain better similarity of prediction context, an\n",
      "the encoding convolutional and max pooling layers is to help adaptive predictor selection strategy is employed. Then the\n",
      "decrease the size of the image data and also the overall space k-means clustering technique uses the spectral vector\n",
      "taken by the data. The major contributions of this work can be correlation coefficient to measure similarity. The outcome of\n",
      "highlighted as: the prediction process is improved by the double snake scan\n",
      "• Compression of hyperspectral images using customized mode and the recursive local average estimation method is\n",
      "autoencoder. utilized for accelerated calculation of the local average.\n",
      "• Greater accuracy achievement from other state of art Báscones et al. (2018) presented a compression algorithm that\n",
      "architectures. decorrelates the image spectrally by using Vector\n",
      "• Fusion of convolutional network and autoencoder along Quantization and Principal Component Analysis (VQPCA).\n",
      "with attention layer for better performance. The spatial correlations are then exploited for compression by\n",
      "The novelty of this paper can be encapsulated as: applying JPEG2000 to the Principal Components [9]. The\n",
      "• The proposed autoencoder is an efficient model. optimized choice of parameters maximized the\n",
      "• The results surpass state of the art architectures. distortion-ratio performance. They also proposed a formula to\n",
      "• Overall, training time is highly effective. determine the algorithm’s configuration for obtaining a result\n",
      "The remaining paper is organized as follows. Section 2 ranging from heavily compressed-low SNR images to low\n",
      "elaborates the recent related works in the domain of HSI compressed-near lossless images.\n",
      "compression. The technologies used by the proposed model Machine Learning strategies, especially in instances of\n",
      "are discussed in Section 3. In Section 4, the proposed Deep Learning, enhance the performance of compression\n",
      "convolutional autoencoder architecture is illustrated. The techniques, as observed from literature. It is proven that the\n",
      "experimental setup and the obtained results of the experiments concept of autoencoder works much better for compression in\n",
      "are shown in Section 5. The results achieved by the proposed every domain. Cheng et al. (2018) [10] presents an\n",
      "model are explained and detailed in Section 6. Lastly, the architecture for lossy image compression using Conventional\n",
      "conclusions along with future work are briefed in Section 7. autoencoder (CAE) to attain higher efficiency while coding.\n",
      "Initially they designed a new CAE architecture and trained the\n",
      "II. Literature Review autoencoder using a loss function based on rate-distortion.\n",
      "Next, feature maps were rotated using principal components\n",
      "HSI compression is a prominent emerging topic of research\n",
      "analysis (PCA) and quantization and entropy coder were\n",
      "for the space industry due to its immense memory size. There\n",
      "applied to generate the codes, achieving a 13.7% BD-rate\n",
      "are several articles published in recent years for this\n",
      "decrease on images from Kodak database as compared to\n",
      "specialized work. Many scientific communities are inclined\n",
      "images from JPEG2000. But the moderate complexity was\n",
      "towards lossless algorithms to preserve the required\n",
      "similar to JPEG2000. In terms of compression in the medical\n",
      "information as much as possible in compression. However,\n",
      "domain, Mishra et al. (2020) [11] used a two-staged\n",
      "in need of higher compression and to reduce the memory size,\n",
      "autoencoder for compressor-decompressor for the purpose of\n",
      "lossy compression algorithms are adopted.\n",
      "compressing malaria RBC cell image patches, which showed\n",
      "To improve the lossy compression performance of HSI,\n",
      "significant improvement over state-of-art algorithms. The\n",
      "Ertem et al. (2020) [6] used an enhanced Spectral-Spatial\n",
      "proposed dual autoencoder model is a good ROI-based loss\n",
      "Adaptive Sparse Representation (SSASR) known as modified\n",
      "compression method with minimum information loss.\n",
      "SSASR. This uses a single PCA transformation in place of398\n",
      "In the field of Hyperspectral image compression, Denge et For compression of images, there exist several techniques,\n",
      "al. (2020) [12] supplied a generative neural network to learn but those techniques cannot be used for HSI compression due\n",
      "the probability distribution of data from random latent code. to their spatial and spectral features. Commonly seen\n",
      "The proposed model stores the HSI, the random normal drawback is the splitting of the dataset [2], [6], [8], [13]. On\n",
      "distribution that supplies the maximum entropy. As a result, splitting the data, the number of neighbors decreases. As a\n",
      "both the compression quality and ratio are controlled directly result, the prediction is limited and affects compression (for\n",
      "through the model. It also uses the pruning technique to learning, input data is less), and apart from poor predictions,\n",
      "eliminate weights that do not affect the compression ratio. To the gradient loss also gets affected. Pre-processing of images\n",
      "minimize the time and memory complexities constraints, a before feeding them to models provides better results [9], [14],\n",
      "complexity-reduced variational autoencoder was designed by [16], [17]. In recent years, many architectures have presented\n",
      "Oliveira et al. (2021) [13]. They also put forward a simple for HSI compression. Few of them are discussed earlier, and\n",
      "entropy model that contained a single parameter to support the the main intuition used behind HSI compression is the\n",
      "input image’s adaptability. It outperformed the CCSDS property of dimension reduction [6]-[8]. In the growing era of\n",
      "122.0-B and had a reasonable rate distortion performance. artificial intelligence, one can compress images effectively\n",
      "This model is able to identify the least global amount of filters with significantly lower computational power [10]-[12]. In\n",
      "for every rate due to its bottleneck size. A lossy compression this paper, we tried to overcome a few of these drawbacks by\n",
      "scheme is proposed by Ouahioune et al. (2021) [14], a avoiding data splitting followed by modified machine\n",
      "combination of 3D wavelet transforms and a super-resolution learning architecture utilization for better comparison results\n",
      "technique based on wavelet learning called wavelet and experimenting with reshaping and normalization\n",
      "learning-based super-resolution compression (WSRC). They techniques for pre-processing.\n",
      "down-sampled the image during encoding which reduced the\n",
      "loss of information and up-sampled it by a super-resolution III. Basic Concepts\n",
      "strategy at the decoder, thus increasing the information\n",
      "The different techniques used for the proposed Hyperspectral\n",
      "compensation. The outcome of the algorithm supplies a\n",
      "Image compression are discussed in this section [18]. This\n",
      "prominent performance, preserves the spectral signature, and\n",
      "section is organized as: A. Convolutional Neural Network\n",
      "generates high-quality images. But with a better resolution\n",
      "(CNN) B. Convolutional Autoencoder, C. Entropy Coding.\n",
      "(high-quality), compression is not much supported in terms of\n",
      "memory size.\n",
      "An extended work of Wang et al. (2019) [15] was proposed A. Convolutional Neural Network (CNN)\n",
      "by Ayma et al. (2020) [16], a dimensional reduction Convolutional Neural Networks (CNNs) are a version of\n",
      "implementation for hyperspectral imaging using orthogonal traditional Artificial Neural Networks (ANNs), consisting of\n",
      "autoencoder (HOAE) to decrease the redundancy. This self-optimized neurons [19]. A CNN, also known as ConvNet,\n",
      "technique helped to learn orthogonal characteristics in a is a specialized Deep Learning model, a sub type of ANN that\n",
      "lower-dimensional vector space by including orthogonal uses an image based input and applies importance-based\n",
      "constraints inside the loss function. The orthogonal features learnable weights and biases on various aspects of the grid\n",
      "aided in achieving better classification rates as compared to pattern data, like images and can distinguish between each of\n",
      "them. The CNN algorithms with some slight modifications\n",
      "ultramodern and typical autoencoders. A lossy Hyperspectral\n",
      "are used for uncountable purposes. Few of the most common\n",
      "compression using the concept of the autoencoder was\n",
      "uses of CNN are food detection [20], hate-speech\n",
      "presented by Dua et al. (2021) [2]. It was represented by a\n",
      "identification system [22], in numbers of medicine purposes\n",
      "combination of max-pooling layer and convolutional layer for\n",
      "[18], [22], image classification [23], and recognition [24],\n",
      "dimensional reduction. The lossy original image is\n",
      "texture synthesis [25], facial analysis [26], [27] and many\n",
      "constructed again by utilizing the transpose of the convolution\n",
      "more. CNNs have many forthcoming spectra as improvement\n",
      "layer. An adaptive arithmetic coder was used to entropy code\n",
      "in the application within radiology, the study of vulnerability\n",
      "the compressed picture for transport or storage. A total\n",
      "in deep neural networks like adversarial examples [28],\n",
      "improvement of 28% was achieved in PSNR and a 21 times\n",
      "pre-trained networks for large required datasets like medical\n",
      "increase in compression ratio was calculated using this model.\n",
      "datasets can be proposed. The principal function of CNN is\n",
      "The compression result is evaluated through classification extracting features from the input with the help of\n",
      "using ultramodern classification algorithms. The proposed back-propagation using multiple rudimentary steps like\n",
      "algorithm proved to be amazingly effective due to its convolution layers, pooling layers, and fully connected or\n",
      "negligible difference in classification accuracy. A technique dense layers [29].\n",
      "of compressing hyperspectral data using a 1D-Convolutional The concept of CNN came from the convolution theorem\n",
      "Autoencoder was introduced by Kuester et al. (2021) [17]. based on the mathematical operator which is anointed\n",
      "The spatial domain is not utilized during compression in order convolution, a specialized category of linear operation. So,\n",
      "to avoid the falsification of the relationship between the mathematically using the convolution theorem, the\n",
      "spectral dimensions and therefore affect the accuracy of convolutional layer can be explained and defined as:\n",
      "∞\n",
      "reconstruction by the model. The given approach locates and ∫ 𝑢(𝜓)𝑣(𝛼−𝜓)𝑑𝜓\n",
      "(𝑢∗𝑣)(𝛼)≜ −∞ (1)\n",
      "extracts compression-relevant characteristics in an efficient 𝑢(𝛼)∗𝑣(𝛼)\n",
      "Mathematically, in equation 1, convolution is the integral\n",
      "manner. The 1D-Convolutional Autoencoder surpasses the\n",
      "of all the space present in one function, u at α time of another\n",
      "Nonlinear Principal Component Analysis (NPCA) and the\n",
      "function, v at α of the continuous variable. The integration is\n",
      "Deep Autoencoder in terms of reconstruction accuracy.\n",
      "from minus infinity to plus infinity over all the dimensions ofHyperspectral Image Compression using Modified Convolutional Autoencoder 399\n",
      "the variable α (can be 1D or 3D variable). The crossed circle for the layers in the encoder of the proposed framework are: a)\n",
      "operation writes down the convolution operation. Figure 1 Convolutional layers, b) Activation function, c) Pooling, d.\n",
      "represents a typical convolutional neural network with its Attention layers, and e) Flattening layers.\n",
      "hidden layers.\n",
      "a) Convolutional layers\n",
      "The convolution layer is the initial layer of CNN that extracts\n",
      "the features from the input. It has sets of filters known as\n",
      "kernels. Convolutional layers using learnable weights and\n",
      "bias forward propagate on the training dataset. As shown in\n",
      "equation 3 it follows the convolutional theorem that is the\n",
      "product of Fourier transform, F(k), G(k) in Fourier space of\n",
      "Figure 1. Convolutional Neural Networks (CNN)\n",
      "two function, f(r), g(r) is same as the convolution of both\n",
      "B. Convolutional Autoencoder functions, i.e.,\n",
      "Autoencoder (AE) is a self-taught learning unsupervised 𝑓(𝑟)⊗⊗𝑔(𝑟)⟺𝐹(𝑘)𝐺(𝑘) (3)\n",
      "neural network framework, composed of encoding stages and\n",
      "decoding stages to reconstruct the given input patterns by b) Activation function\n",
      "dropping the noises and data dimension reduction. AE takes a The activation or threshold function is a mathematical\n",
      "fragment of input patterns and produces a discrete latent code function of a node applied to a given set of inputs. In\n",
      "[30]. They execute by representing the input in a latent-space simplified terms, it is a feature to decide the activation of a\n",
      "after its compression (encoding the data) of a 1-D vector, given neuron in the exact way biological neurons get activated\n",
      "known as the bottleneck, and reconstructing the output from using simulation. It is a function used in the neural network to\n",
      "this generated representation (decoding the data) [31]. The help the network learn complex features in the input data,\n",
      "higher level of network hardwiring by adding convolutional represented in Figure 3. The task of this function is to use the\n",
      "operation in the existing autoencoder network is understood weighted sum of input nodes and generate an output in the\n",
      "as Convolutional Autoencoder (CAE) [46]. Figure. 2 given layer of the neural network and fed to another layer or as\n",
      "illustrates the structural framework of a convolutional output [44].\n",
      "autoencoder.\n",
      "Figure 3. Activation Function\n",
      "Figure 2. Convolutional Auto Encoder\n",
      "Several activation functions, diverged in terms of linear\n",
      "AE is used for de-noising and dimension reduction\n",
      "activation function and non-linear activation functions like\n",
      "purposes. AE is applicable for a wide range of purposes in the\n",
      "sigmoid, Hyperbolic Tangent (tanh), exponential linear units\n",
      "modern world in remote sensing [32], classification [33],\n",
      "(ELUs), etc. are used in neural networks. The proposed\n",
      "deception detection [34], medicines [35], removal of noise [36]\n",
      "method made use of two activation functions. ReLU\n",
      "and watermark [37], image reconstruction [38] and generation\n",
      "(Rectified Linear Unit) is used which supplies a linear\n",
      "[39]. The greater the accuracy of the autoencoder, the more\n",
      "function impression. It utilizes a derivative function and\n",
      "similar the generated and the original data are [40]. Therefore,\n",
      "permits back-propagation with computational efficiency\n",
      "AE is divided into two parts: 1. Encoder and 2. Decoder.\n",
      "simultaneously. The ReLU function only works for positive\n",
      "input, which can be understood by equation 4 where F(y) is\n",
      "1) Encoder\n",
      "the function. The mathematical representation of the ReLU\n",
      "An encoder is a fully connected network that uses a\n",
      "function is:\n",
      "feed-forward system to compress an input by encoding the\n",
      "𝑓(𝑦)=max(0,𝑦) (4)\n",
      "input image in a reduced dimension and representing it in a\n",
      "Another activation function used is an identity function,\n",
      "latent space. The mapping functions are non-linear. The\n",
      "also called a linear function. The activation is proportional to\n",
      "standard form is:\n",
      "𝑚 =𝑓(𝑦)= 1 (2) the given input and represented in equation 5.\n",
      "𝑖 𝑖 1+exp (−𝑤1𝑦𝑖+𝑣1) 𝑓(𝑦)= 𝑦 (5)\n",
      "In equation 2, is a function w and is the encoding weight.\n",
      "1\n",
      "Its biased vector is v 1. c) Pooling\n",
      "An encoder is a self-learning forward propagating\n",
      "Pooling layers are the next layer after the convolutional layers\n",
      "convolutional neural network consisting of many building\n",
      "and are operated for spatial dimension reduction of feature\n",
      "blocks of contrasting functions as its layer. The blocks used400\n",
      "maps, i.e., they reduce the amount of learning parameters. A 2) Decoder\n",
      "pooling layer down-samples the data size using spatial A decoder is the second component of an autoencoder that\n",
      "variances. Max pooling selects a maximum element from the maps the code to reconstruct the compressed version of the\n",
      "region of the filtered feature map as represented in equation 6. in)-1put. A decoder is the inverse CNN structure, which\n",
      "produces output using the 1D vector. The goal of the AE is to\n",
      "𝑜𝑢𝑡𝑝𝑢𝑡= [1+𝑖𝑛𝑝𝑢𝑡+2×𝑝𝑎𝑑𝑑𝑖𝑛𝑔[0]−𝑑𝑖𝑙𝑎𝑡𝑖𝑜𝑛[0]×(𝑘𝑒𝑟𝑛𝑒𝑙𝑠𝑖𝑧𝑒[0]−1)−1] (6) produce an identical copy of the input. Thus, the decoder\n",
      "𝑠𝑡𝑟𝑖𝑑𝑒[0] architecture has to be a mirror image of the encoder. The basis\n",
      "of the architecture of a decoder is that the input and output\n",
      "d) Attention layers\n",
      "dimensionalities must be equal. The decoder takes the encoder\n",
      "In conventional neural networks, cognitive attention can be\n",
      "output with the bottleneck layer, and recreates/regenerates the\n",
      "imitated using a technique called attention. The attention\n",
      "input. The decoder network consists of 3 layers: a) Dense\n",
      "mechanism is the mechanism that helps the neural network to\n",
      "layer, b) Deconvolution, c) Upsampling as shown in figure. 5.\n",
      "memorize a long sequence of data. The attention layer is a\n",
      "conduit between the encoder and the decoder that transfers\n",
      "a) Dense layer\n",
      "information from hidden states of encoder to the decoder. It\n",
      "A dense layer is the most basic layer in neural networks that\n",
      "aids a neural network in the memorization of a large series of\n",
      "feeds its neurons all the output of the preceding layer,\n",
      "data. The model can focus selectively on significant parts of\n",
      "supplying one output for every neuron to the next layer. It is a\n",
      "the input sequence, and hence identify the relationship\n",
      "regular deep fully connected neural network, a frequently\n",
      "between them. The attention layer is built to permit the use of\n",
      "implemented layer. The dense layer mainly performs\n",
      "the most relevant parts of the input sequence flexibly to\n",
      "matrix-vector multiplication, where the used values are the\n",
      "decoder by accumulation of all encoded input vectors to a\n",
      "self-trained parameters that can be updated through\n",
      "weighted combination, with the greatest weights received by\n",
      "back-propagation. It applies several operations like scaling,\n",
      "the most relevant vectors [42]. Normalization of the output\n",
      "rotation and translation on a vector, but primarily they change\n",
      "score of a feed-forward neural network is represented by a\n",
      "the vector dimensions, generating an output of an m-D vector.\n",
      "function that preserves the congruence between input at j and\n",
      "output at i generates the attention weights.\n",
      "b) Deconvolution\n",
      "𝛽 =\n",
      "exp (𝑎𝑖𝑗)\n",
      "(7)\n",
      "𝑖𝑗 ∑𝜏 𝑟𝑦\n",
      "=1exp (𝑎𝑖𝑟)\n",
      "Deconvolution is a mathematical operator that transposes\n",
      "β are the weights, τ is window size, and the sum of all convolution. It is an unsupervised technique for convolutional\n",
      "ij y\n",
      "weights within one window is equal to 1 in equation 7. decomposition based on a sparsity constraint [44]. Its main\n",
      "application is for those networks which reconstruct the input.\n",
      "e) Flattening layer. In deconvolution, the dimension of output is more than that of\n",
      "input. As deconvolution is the transpose of convolution, it can\n",
      "Flattening is the process of converting multiple-dimension\n",
      "be mathematically expressed in the form of linear system as\n",
      "input to a single-dimension array. The output generated by the\n",
      "shown in equation 8.\n",
      "convolutional layers is flattened to a single 1-D feature tensor.\n",
      "[𝑜]=[𝐾]⋅[𝑦]+[𝑒] (8)\n",
      "In simple terms, a flattening layer merges all the input layers\n",
      "Where, [y] is the matrix of unknown signals, [o] is a vector\n",
      "into a single layer. The flattening layer adds an extra channel\n",
      "of observations, [K] is a known matrix, and [e] a vector of\n",
      "dimension to the input shape without a feature axis [43]. The\n",
      "random errors.\n",
      "use of flattening layers is to permit changes to the input shape\n",
      "from a vector of n-D matrixes to the correct shape for\n",
      "c) Upsampling\n",
      "interpretation of dense layer. It collapses an input spatial\n",
      "dimension to a channel dimension. For example, if the output Upsampling is a technique used to raise the sampling rate by\n",
      "given by a convolutional layer is a 3D array of shapes, insertion of zero-valued samples in between the original\n",
      "32x16x8 then after flattening the shape will be 32*16*8=4096 samples. Upsampling is the manipulation of signals for the\n",
      "units. The encoder architecture elaborated is represented in artificial increment of the sampling rate. Upsampling\n",
      "the figure. 4. improves resolution, anti-aliasing filter performance and\n",
      "reduces errors. In simple words upsampling is a simple\n",
      "scaling up of input image using nearest neighbours (bi-linear\n",
      "upsampling). Considering s is the factor for upsampling\n",
      "operation, then the (i, j)th element of the upsampling matrix\n",
      "u in equation 9.\n",
      "a,b\n",
      "{𝑢 }\n",
      "=↑𝑠(𝛽[𝑖−𝑗])=𝛽[𝑖\n",
      "−𝑗]=𝑏[𝑖−𝑠𝑗] (9)\n",
      "𝑎,𝑏 𝑖,𝑗 𝑠\n",
      "Figure 4. EncoderHyperspectral Image Compression using Modified Convolutional Autoencoder 401\n",
      "Algorithm:\n",
      "// Bitwise Normalization\n",
      "Normalize data using z- score normalization\n",
      "Reshape to 4-D array # reshaping into (1, rw, cl, and b).\n",
      "// Encoder Model\n",
      "Conv2D layer with 220 filters and ReLU function;\n",
      "Max pooling2D layer;\n",
      "Conv2D layer with 128 filters and ReLU function;\n",
      "Max pooling2D layer;\n",
      "Conv2D layer with 64 filters and ReLU function;\n",
      "Max pooling2D layer;\n",
      "Conv2D layer with 32 filters and ReLU function;\n",
      "Max pooling2D layer;\n",
      "Figure 5. Decoder Attention layer;\n",
      "Flattening layer;\n",
      "IV. Proposed Method // Decode Model\n",
      "Dense layer with ReLU function;\n",
      "First, normalization of HSI images is done to avoid input Layer reshape;\n",
      "shape errors followed by optimization of the neural network. Upsampling2D layer;\n",
      "An Adam optimizer is applied with its parameters, the Conv2DTranspose layer with 32 filters and ReLU function;\n",
      "learning rate of 0.0009, default for both the exponential decay, Upsampling2D layer;\n",
      "with beta_1=0.9 and beta_2=0.999 [45], followed by model Conv2DTranspose layer with 64 filters and ReLU function;\n",
      "implementation. Upsampling2D layer;\n",
      "This paper uses the dimension reduction property of the Conv2DTranspose layer with 128 filters and ReLU function;\n",
      "autoencoder for HSI compression. The illustration of the Upsampling2D layer;\n",
      "proposed autoencoder architecture is shown in algorithm 1. Conv2DTranspose layer with 220 filters and ReLU function;\n",
      "Elaborating the framework, both encoder and decoder have a Conv2DTranspose layer with 220 filters and Linear function;\n",
      "set of convolutional, max-pooling, and dense layers. As the Resize to (rw, cl)\n",
      "first step, input fed to three convolutional layers paired with\n",
      "max-pooling layers, a padding size of kernel = 2, 2 was used.\n",
      "The output obtained from the encoder is the input for the\n",
      "The first convolutional layer has 128 filters and a ReLU\n",
      "decoder. So, 8192 units are taken as the unit for the dense\n",
      "activation function if the number of bands is greater than 128.\n",
      "layer. It is followed by two deconvolutional layers, or\n",
      "The second layer with 64 filters is included, followed by the\n",
      "transpose of convolutional layers, further followed by\n",
      "third convolutional layer of 32 kernels with the tanh activation\n",
      "upsampling layers. Then again three deconvolutional layers\n",
      "function. Every convolutional layer is connected to a max\n",
      "are added. A regenerated image of a similar shape to that of\n",
      "pool layer for the reduction of pixels from earlier\n",
      "the input image is obtained as the final output. To minimize\n",
      "convolutional layers, to reduce input Dimensionality. Lastly,\n",
      "loss as much as possible, 120 to 350 epochs are used for\n",
      "after the third convolutional layer, an attention layer is added\n",
      "training. Figure 6 shows the pipeline of the proposed\n",
      "followed by a flattening layer of 8192 units.\n",
      "convolutional autoencoder.\n",
      "ALGORITHM 1: MODIFIED AUTOENCODER ALGORITHM FOR\n",
      "COMPRESSION\n",
      "Result: Decoded bit streams of the compressed image\n",
      "Input: Hyperspectral Image, his, of dimension\n",
      "(rw x cl x b), Here rw = number of rows,\n",
      "cl = number of columns, b = number of bands\n",
      "Attention Layer: Generate custom layer using keras\n",
      "Default layer Class. Four function as arguments for\n",
      "Keras custom layer generation rule. Function build ()\n",
      "To define weight and biases (w and B).\n",
      "The call () for multilayer perceptron (MLP) with tanh\n",
      "Figure 6. Proposed Convolutional Autoencoder Architecture\n",
      "Followed by softmax layer. To return the shape of the\n",
      "built layer, a compute_output_shape () function is added,\n",
      "V. Implementation and Results\n",
      "along with get_config () for gathering all the information\n",
      "About the custom model. To validate the proposed model simulation results are\n",
      "Initial Parameters: For optimized neural network presented in this section. Here the details of the datasets used,\n",
      "Adam optimization algorithm is taken, with the experimental configurations, and the obtained results are\n",
      "α = 0.0009, β1 = 0.9 and β2 = 0.999. Here α represents mentioned. The RGB images of the datasets are shown in\n",
      "the learning rate of the model, and β1 and β2 Figure 7. The section is subdivided as:\n",
      "respectively are the exponential A. Dataset, B. Experimental setup, C. Comparison and\n",
      "Decay rates of 1st and 2nd moment estimation. Analysis of Algorithms\n",
      "Representation: The image is normalized using the z score\n",
      "And reshaped into a 4-D matrix, i.e. (1, rw, cl, b).402\n",
      "A. Dataset\n",
      "To assess the proposed compression technique, widely used 4) University of Pavia\n",
      "Hyperspectral datasets are adopted. The framework is In this paper it is the fourth HSI dataset used for compression.\n",
      "performed in four real-world datasets: Indian Pines, Kennedy The University of Pavia dataset is an HSI dataset acquired\n",
      "Space Center (KSC), the Salinas Scene, and the University of over Pavia, northern Italy in 2003 by an airborne reflectance\n",
      "Pavia datasets. For research purposes, these datasets are optical spectrometer sensor, the Reflective Optics\n",
      "publicly available in [41]. Each dataset has multiple sets of a Spectrographic Imaging System, ROSIS-03. Initially, the\n",
      "single image. Table 1 specifies the number of sets present in Pavia University dataset was of 610*610 pixels with 115\n",
      "each dataset. We will briefly discuss each HSI dataset in its spectral bands, but some images on the sample had no\n",
      "sub division: 1 Indian Pines, 2. Kennedy Space Center (KSC), information in it, so it was discarded to 610X340 pixels and\n",
      "3. Salinas Scene, and 4. University of Pavia due to the presence of noise, 15 wavebands were removed, so\n",
      "the corrected dataset consisted of 610X340 pixels and 103\n",
      "Table 1. Hyperspectral Imaging Dataset Used spectral bands. The ground truth is differentiated into 9\n",
      "classes shown in table 1.\n",
      "DATASET PIXEL BAND CLASS IMAGE\n",
      "No. B. Experimental setup\n",
      "Indian 145*145 200 16 200\n",
      "The proposed compression framework and all other\n",
      "Pines\n",
      "architectures are implemented in the personal hardware\n",
      "Kennedy 512*614 176 13 126\n",
      "workstation powered by windows 11 with Intel(R) Core (TM)\n",
      "Space\n",
      "i5-8250U 8th generation and CPU @ 1.80 GHz and 16GB\n",
      "Center\n",
      "Random Access Memory (RAM), and along with this, all the\n",
      "(KSC)\n",
      "neural network libraries like Keras, TensorFlow used are\n",
      "Salinas 512*217 204 16 204\n",
      "coded in python 3.8.8. For the effectiveness evaluation of the\n",
      "Scene\n",
      "proposed framework, two measurement metrics used are Peak\n",
      "Signal to Noise Ratio (PSNR), and Compression Ratio (CR).\n",
      "1) Indian Pines\n",
      "The ratio of maximum signal power possible and the\n",
      "Indian Pines is the first dataset used for hyperspectral image\n",
      "corrupting noise power affecting the representative's fidelity\n",
      "compression in this paper. In June 1992, NASA used an\n",
      "is known as PSNR. PSNR is utilized for measuring quality of\n",
      "AVIRIS sensor to gather the hyperspectral scene over Indian\n",
      "the reconstructed lossy compression codecs, also known as\n",
      "Pines, North-western Indiana test site. The images are of\n",
      "image\n",
      "145X145 pixels and have 220 spectral reflectance bands in the\n",
      "wavelength range 0.4–2.5 10^ (-6) meters (µm). The 220\n",
      "wavebands of the image were continuously captured via\n",
      "AVIRIS on the specified wavelength and at approximately\n",
      "20m of spatial resolution. Recently, by removing the water\n",
      "absorption region covering bands ({104-108}, {150-163},\n",
      "220), the dataset is corrected by reducing 220 bands to 200\n",
      "bands. The ground truth is categorized into sixteen classes,\n",
      "shown in table 1.\n",
      "2) Kennedy Space Center (KSC)\n",
      "The second real-world dataset used is the site of mixed\n",
      "Indian Kennedy Salinas Scene University of\n",
      "vegetation over the Kennedy Space Center (KSC), Florida,\n",
      "Pines Space Center Pavia\n",
      "and USA which was acquired in 1996 by the National\n",
      "(KSC)\n",
      "Aeronautics and Space Administration (NASA) Airborne\n",
      "Visible/Infrared Imaging Spectrometer instrument. It had 224 Figure 7. RGB image of the HSI Dataset used\n",
      "spectral bands when it was collected ranging from 0.4 to\n",
      "quality metric. Equation 10 expressed PSNR mathematically,\n",
      "2.5μm wavelengths, with a spatial size of 512 × 614 pixels\n",
      "where is the maximum pixel value possible and mse\n",
      "with 5211 labelled pixels, and 18m spatial resolution. Due to\n",
      "represents mean square error, which is a quantification of the\n",
      "the low signal-to-noise ratio (SNR) and water absorption, 48\n",
      "error difference between the original and the reconstructed\n",
      "bands are discarded during pre-processing. As a result, for the\n",
      "image.\n",
      "classification, 176 spectral bands are used. In the original\n",
      "dataset and the ground truth, 13 land cover types are 𝑃𝑆𝑁𝑅\n",
      "=𝑀𝑃𝑝\n",
      "(10)\n",
      "𝑚𝑠𝑒\n",
      "represented in table 1. Compression Ratio (CR) also called Data Compression\n",
      "Ratio, and compression power is the measurement metric of\n",
      "3) Salinas Scene relative reduction of data representation size achieved by\n",
      "The third dataset used in this paper is the Salina scene, compression techniques. In simple words, CR is the ratio of\n",
      "acquired over Salinas Valley, California, USA, by 224 band uncompressed to compressed size as shown in equation 11.\n",
      "AVIRIS Imagining spectrometer sensor, and characterized via 𝑈𝑛𝑐𝑜𝑚𝑝𝑟𝑒𝑠𝑠𝑒𝑑 (𝑂𝑟𝑖𝑔𝑖𝑛𝑎𝑙)𝑠𝑖𝑧𝑒 𝑜𝑓 𝑖𝑚𝑎𝑔𝑒\n",
      "𝐶𝑅 = (11)\n",
      "high spatial resolution of 3.7-meter per pixel. The dimension 𝐶𝑜𝑚𝑝𝑟𝑒𝑠𝑠𝑒𝑑 𝑠𝑖𝑧𝑒 𝑜𝑓 𝑖𝑚𝑎𝑔𝑒\n",
      "of the Salinas scene was 512X217 pixels with 224 spectral The intention of compression is to minimize the amount of\n",
      "bands, but 20 bands of water absorption region were discarded: input data, simultaneously preserving as much information as\n",
      "{108-112}, {154,167}, 224. As shown in table 1, 16 classes feasible. To put it another way, it means optimizing the lossy\n",
      "are categorized on the ground truth. data with maximization of CR and PSNR.Hyperspectral Image Compression using Modified Convolutional Autoencoder 403\n",
      "A. Comparison and Analysis of Algorithms 2) Filters\n",
      "This section discusses the comparative comparison carried out The proposed CAE framework uses N input neurons with H\n",
      "to inspect the quantitative superiority of the proposed HIS hidden neurons, where N stands for the number of spectral\n",
      "compression framework including the state-of-art: NFTD + bands in each dataset. As the framework is completely\n",
      "PCA, and 3D DWT+SVR. We explored and analysed the connected, every hidden layer is attached to every input\n",
      "behaviour of AE for better performance on the basis of PSNR neuron. Thus, on the whole, the N connection acts as a filter,\n",
      "and CR. since it filters out some information from the input\n",
      "representing wavelengths and simultaneously overemphasize\n",
      "others. For improvement in the model, we experimented with\n",
      "various hidden layers, such as the attention layer, flattening\n",
      "layer, and dense layer in both encoder and decoder. Six\n",
      "experimental models are compared in table 2. The size of\n",
      "every layer varies as per the dataset dimension. From the table,\n",
      "it can be understood that the autoencoder with attention layer\n",
      "followed by flattening and dense layer performs best\n",
      "compared to other architectures on the basis of CR and PSNR,\n",
      "and size of dense layer depends proportionally to the size of\n",
      "data.\n",
      "3) Comparison\n",
      "For efficiency evaluation of our proposed framework, we\n",
      "evaluated based on compression ratio and PSNR obtained\n",
      "from three state-of-art algorithms. We implemented the\n",
      "Figure 8. Model Loss\n",
      "NFTD + PCA by taking principal components as 16, as the\n",
      "1) Construction dataset consists of large spectral bands. Along with this, we\n",
      "Initially, the proposed architecture’s performance is assessed implemented 3D DWT+SVR and CAE proposed in [2]. In\n",
      "via the calculation of the obtained loss against the number of table 3, a comparison of the average results is represented\n",
      "epoch functions. Training and testing splitting was randomly because of its stability. The experiment was executed 20 times\n",
      "distributed for better performance. The obtained graph of so that it authenticates the coherence of the proposed\n",
      "gained loss (y-axis) based on epochs (x-axis) is shown in architecture. Table 4 shows the top 10 achieved PSNR for the\n",
      "Figure 8. From the graph we can suggest, in between 0 to 25 University of Pavia dataset. It is observed that the modified\n",
      "epochs the training loss was immense with lots of fluctuations CAE outperforms all other algorithms on the basis of CR and\n",
      "and after 25 epochs the loss gradually declined and in between PSNR. The proposed architecture performs incredibly well\n",
      "300 to 350 it started attending consistency, due to its static for the Salinas dataset. The reason for the better performance\n",
      "level, the optimal number of epochs selected for the model is its 3.7 m per pixel spatial resolution. In table 5, we compare\n",
      "was 350 epochs. Due to variation in dataset dimension, each the original size of each file to the obtained compressed file\n",
      "filter size (kernel size) is tuned as per the input size. To avoid size in bytes. The compressed file size of the dataset obtained\n",
      "data loss and image splitting, we have not considered by the University of Pavia decreased the most, and the\n",
      "partitioning the datasets into the training and testing phase as original file size decreased by 9655 times.\n",
      "it will result in the splitting of spectral dimensions that will The size of the original Salinas dataset undergoes around\n",
      "cause image distortion. Initially, the proposed architecture 7950 times decrement and for the KSC dataset, the original\n",
      "comprised of three convolutional layers, with each being file size is compressed by 1177 times, and 2713 times\n",
      "connected to a max-pooling layer, then bottleneck layers as reduction is seen in Indian pines compressed file size. The\n",
      "encoders, and in the decoder, five de-convolutional layers results obtained from the modified CAE and other state-of-art\n",
      "(transposed convolution layers) along with upsampling. algorithms are graphically represented in Figure 9. Figure 9a\n",
      "shows that in the\n",
      "Table 2. Filter comparison\n",
      "MODELS (M) ATTENTION DENSE LAYER CR PSNR\n",
      "LAY ER ENCODER DECODER\n",
      "DIMENSION 8192\n",
      "M1 ✔ ✖ ✖ 441.238 53.008\n",
      "M2 ✖ ✔ ✖ 389.043 51.917\n",
      "M3 ✖ ✖ ✔ 502.576 53.893\n",
      "M4 ✔ ✔ ✖ 1105.673 48.128404\n",
      "Table 3. Comparison\n",
      "DATASET NFTD+PCA 3D DWT+SVR CAE MODIFIED CAE\n",
      "PSNR CR PSNR CR PSNR CR PSNR CR\n",
      "Indian Pines 49.68 130.25 44.19 27.02 55.19 128.33 55.89 2713.95\n",
      "Kennedy Space 47.06 235.12 41.56 26.35 53.32 371.67 53.55 5756.14\n",
      "Center (KSC)\n",
      "Salinas Scene 46.47 272.23 42.28 21.53 54.46 447.42 58.13 7950.95\n",
      "University of 47.11 137.51 43.59 25.95 55.26 157.71 56.74 3194.47\n",
      "Pavia\n",
      "Table 4. Top 10 achieved PSNR for the University of Pavia\n",
      "dataset\n",
      "University of Pavia\n",
      "EXPERIMENT NO. PSNR CR\n",
      "EXPERIMENT 1 52.06 6521.80\n",
      "EXPERIMENT 3 59.30 7049.02\n",
      "EXPERIMENT 4 51.00 8561.31\n",
      "EXPERIMENT 7 54.21 6958.42\n",
      "EXPERIMENT 8 52.69 4237.65\n",
      "EXPERIMENT 9 57.28 7562.60\n",
      "EXPERIMENT 11 55.13 6851.32\n",
      "EXPERIMENT 12 51.33 7963.14 Figure 9a. Comparison of CR of proposed model with\n",
      "EXPERIMENT 15 50.3 6753.78 state-of-art algorithms\n",
      "EXPERIMENT 19 52.6 6025.36\n",
      "Table 5. Size Comparison\n",
      "DATASET ORIGINAL COMPRESSED\n",
      "SIZE SIZE\n",
      "(in Bytes) (in Bytes)\n",
      "Indian Pines 6296374 2320\n",
      "Kennedy Space 56824624 48272\n",
      "Center (KSC)\n",
      "Salinas Scene 27605707 3472\n",
      "University of Pavia 95320136 9872\n",
      "proposed modified CAE, represented by yellow bar, CR is\n",
      "increased by approx. 18 times than the state-of-art CAE\n",
      "method, 200 times increment from 3D DWT+SVR, and 25 Figure 9b. Comparison of PSNR of proposed model with\n",
      "times of NFTD+PCA. The CR for the Salinas dataset state-of-art algorithms\n",
      "achieved is 355 times better in modified CAE than 3D\n",
      "DWT+SVR. Figure 9. Comparison graph for CR, PSNR\n",
      "Figure 9b compares the PSNR gained in the proposed\n",
      "The absolute difference between modified CAE and CAE\n",
      "architecture, signified by yellow bar, to other state-of-art\n",
      "in PSNR achieved for the Salinas dataset is 3.67 units. The\n",
      "compression architecture and confirms that the modified CAE\n",
      "reason behind the improvement in CR and PSNR is the\n",
      "performed better by around 5% in terms of PSNR. The\n",
      "addition of the attention layer in the encoder that memorizes\n",
      "estimation for only 0.23 unit increment in PSNR for the KSC\n",
      "large sequences of spatial features, which consequently\n",
      "dataset is that due to the larger dimension (512 x 614 x 176),\n",
      "improves the compression rate after decoding. The illustration\n",
      "the quality improvement is slighter during compression.\n",
      "of the original image along with the image reconstructed by\n",
      "the modified CAE is shown in Figure 10.\n",
      "XI. Discussion\n",
      "The main problem with hyperspectral image, apart from its\n",
      "high cost, is the large storage requirement due to its multiple\n",
      "bands and spectral and spatial redundancy. As compared to\n",
      "RGB images (3 band imagery), usually HSI consists of more\n",
      "than 100 bands, for storage of spectral information from each\n",
      "band. As a result, the data size is immense.\n",
      "The main innovation and the primary goal of this work is to\n",
      "compress the data with as less loss of information as possibleHyperspectral Image Compression using Modified Convolutional Autoencoder 405\n",
      "utilizing the strength of an unsupervised artificial neural suitable for identifying features and providing it to CNN\n",
      "network, autoencoder, i.e., reconstruction of compression data that performs feature extraction. The method confirms that\n",
      "from the reduced encoded representation as similar to the the addition of the attention layer and flattening layer to\n",
      "original input as possible by extracting key features of the the autoencoder assist better image compression than\n",
      "hyperspectral Images and storing it into a 3D tensor. The state-of-art algorithms.\n",
      "depressed version can be reconstructed in its original using\n",
      "the decoder, as using transpose convolutional layers reverses\n",
      "XII. Conclusion & Future Work\n",
      "the steps of CNN.\n",
      "In this work, we employ a modified convolutional\n",
      "autoencoder for compression of hyperspectral images. Along\n",
      "with a fundamental convolutional autoencoder framework, a\n",
      "few modifications are made like an attention layer is added to\n",
      "the encoder, a flattening layer as the bottleneck, and a dense\n",
      "layer is connected in the decoder. The algorithm is tested for\n",
      "its compression performance on four benchmark\n",
      "hyperspectral datasets that are Kennedy Space Center, Indian\n",
      "Pines, Salinas Scene, and the University of Pavia dataset. The\n",
      "achieved results depict that the proposed algorithm is able to\n",
      "perform significantly better than the compared work with\n",
      "respect to both compression ratio and peak-signal-to-noise\n",
      "ratio. As the properties of each used image differ from others,\n",
      "the obtained result varies for each dataset. From the\n",
      "Figure 10. Original image (left) and reconstructed image state-of-art, CAE CR increased by around 18 times and a 5%\n",
      "(right) gain is obtained in PSNR for the proposed architecture, and\n",
      "apart from this, a maximum of 7950 times drop is seen in the\n",
      "However, [2] used entropy coding as the bottleneck to\n",
      "compressed file size to that of the original file size.\n",
      "minimize the number of its bits for a unique representation of\n",
      "In terms of future work on compression of hyperspectral\n",
      "input data. It is a lossless coding technique that uses code\n",
      "images, a variety of autoencoders can be trained for\n",
      "words for decoding, and even a corrupted single bit in the\n",
      "compression other than convolutional autoencoders, and\n",
      "code word can make the entire message corrupted. Along with\n",
      "neural network architectures like recurrent neural networks,\n",
      "this drawback, another one, is its limitation on the precision of\n",
      "and many other approaches can be implemented. The\n",
      "the encoded number, thus limiting the number of symbols\n",
      "architectures can be further modified by fine-tuning and\n",
      "within the code word to be encoded. The experiments show\n",
      "pre-processing the hyperspectral images, and the model can\n",
      "that the architecture proposed in the paper outperforms\n",
      "be better optimized with Stochastic Gradient Descent (SGD)\n",
      "state-of-art compression techniques, using the following\n",
      "as a parameter followed by cross-entropy for loss function.\n",
      "configuration: input of size according to its data dimension is\n",
      "Keeping in mind the dimension of each image, better\n",
      "fed to three consecutive convolutional layers accompanied by\n",
      "performance can be achieved with complex neural networks\n",
      "a max-pooling layer of each, further connected to an attention\n",
      "with higher computational power and powerful GPU. By the\n",
      "layer as encoder and flattening layer as the bottleneck, and the\n",
      "usage of higher computing power and with improved and\n",
      "decoder consists of a dense layer followed by five\n",
      "modified hardware, the computational time can be decreased.\n",
      "deconvolutional layers along with upsampling layers for\n",
      "reconstructing the compressed image. The baseline of image\n",
      "References\n",
      "compression is compressing the data and then reconstructing\n",
      "the image by decompression for compression of data encoder\n",
      "is required, and for decompression of data decoder is needed.\n",
      "An autoencoder is the sole composition of encoder and [1] R. Dusselaar & M. Paul, “Hyperspectral image\n",
      "compression approaches: opportunities, challenges, and\n",
      "decoder. In general, the efficient neural network for dealing\n",
      "future directions: discussion,” JOSA A, vol. 34, no. 12, pp.\n",
      "with an image is a convolutional neural network without CNN\n",
      "2170-2180, 2017.\n",
      "computational time, and computational power required will\n",
      "be immense and along with this, the neighborhood [2] Y. Dua, R. S. Singh, K. Parwani & S. Lunagariya, V.\n",
      "Kumar, “Convolution Neural Network based lossy\n",
      "information of each pixel will be lost, so considering both the\n",
      "compression of hyperspectral images,” Signal Processing:\n",
      "intuition, the combination of autoencoder with CNN is the\n",
      "Image Communication, vol. 95, p. 116255, 2021.\n",
      "most coherent architecture for image compression. The\n",
      "[3] NASA, 123.0-b-info testdata, 2015, URL: [link]\n",
      "advantages of the proposed architecture, modified CAE are as\n",
      "[4] “Hyperspectral Image Processing,” in Science Direct\n",
      "follows:\n",
      "Topics, Elsevier, [link].\n",
      "• Convolutional Autoencoder: Autoencoders are data\n",
      "[5] R. Yamashita, M. Nishio, R. K. G. Do & K. Togashi,\n",
      "compression models, used to encode input data to smaller\n",
      "“Convolutional neural networks: an overview and\n",
      "dimension representatives. The dimension reduction\n",
      "application in radiology,” Insights into imaging, vol. 9,\n",
      "attribute of autoencoder in addition to the feature\n",
      "no. 4, pp. 611-629, 2018.\n",
      "extraction attribute of CNN results in an efficient image\n",
      "[6] A. Ertem, A. C. Karaca, O. Urhan & M. K. Güllü,\n",
      "compression technique.\n",
      "“Superpixel based compression of hyperspectral image\n",
      "• Attention mechanism: The ability to identify the with modified dictionary and sparse representation,”\n",
      "information most relevant to accomplishing the given task\n",
      "from input makes the attention mechanism incredibly406\n",
      "International Journal of Remote Sensing, vol. 41, no. 16, Proceedings of the 22nd ACM international conference\n",
      "pp. 6307-6324, 2020. on Multimedia, pp. 1085-1088, 2014.\n",
      "[7] Y. Barrios, A. Rodríguez, A. Sánchez, A. Pérez, S. López [21] B. Gambäck & U. K. Sikdar, “Using convolutional neural\n",
      "& A. Otero, R. Sarmiento, “Lossy hyperspectral image networks to classify hate-speech,” in Proceedings of the\n",
      "compression on a re-configurable and fault-tolerant first workshop on abusive language online, pp. 85-90,\n",
      "fpga-based adaptive computing platform,” Electronics, 2017.\n",
      "vol. 9, no. 10, p. 1576, 2020. [22] S. M. Anwar, M. Majid, A. Qayyum, M. Awais, M.\n",
      "[8] F. Zhu, H. Wang, L. Yang, C. Li & S. Wang, “Lossless Alnowami & M. K. Khan, “Medical image analysis using\n",
      "Compression for Hyperspectral Images based on convolutional neural networks: a review,” Journal of\n",
      "Adaptive Band Selection and Adaptive Predictor medical systems, vol. 42, no. 11, pp. 1-13, 2018.\n",
      "Selection,” KSII Transactions on Internet and [23] F. Sultana, A. Sufian, and P. Dutta, “Advancements in\n",
      "Information Systems (TIIS), vol. 14, no. 8, pp. 3295-3311, image classification using convolutional neural network,”\n",
      "2020. in Fourth International Conference on Research in\n",
      "[9] D. Báscones, C. González & D. Mozos, “Hyperspectral Computational Intelligence and Communication\n",
      "image compression using vector quantization, PCA and Networks (ICRCICN), pp. 122-129, 2018.\n",
      "JPEG2000,” Remote sensing, vol. 10, no. 6, p. 907, 2018. [24] S. Hijazi, R. Kumar & C. Rowen, “Using convolutional\n",
      "[10] Z. Cheng, H. Sun, M. Takeuchi & J. Katto, “Deep neural networks for image recognition,” Cadence Design\n",
      "convolutional autoencoder-based lossy image Systems Inc.: San Jose, CA, USA, 2015.\n",
      "compression,” in Picture Coding Symposium (PCS), [25] L. Gatys, A. S. Ecker & M. Bethge, \"Texture synthesis\n",
      "2018, pp. 253-257. using convolutional neural networks,\" in Advances in\n",
      "[11] D. Mishra, S. K. Singh & R. K. Singh, “Lossy Medical neural information processing systems, pp. 28, 2015.\n",
      "Image Compression using Residual Learning-based Dual [26] B. Fasel, \"Robust face analysis using convolutional\n",
      "Autoencoder Model,” in IEEE 7th Uttar Pradesh Section neural networks,\" in Object recognition supported by\n",
      "International Conference on Electrical, Electronics and user interaction for service robots, vol. 2, pp. 40-43,\n",
      "Computer Engineering (UPCON), pp. 1-5, 2020. 2002.\n",
      "[12] C. Deng, Y. Cen, and L. Zhang, “Learning-based [27] C. Pramerdorfer & M. Kampel, “Facial expression\n",
      "hyperspectral imagery compression through generative recognition using convolutional neural networks: state of\n",
      "neural networks,” Remote Sensing, vol. 12, no. 21, p. the art,” ArXiv preprint arXiv: 1612.02903, 2016.\n",
      "3657, 2020. [28] I. J. Goodfellow, J. Shlens & C. Szegedy, “Explaining and\n",
      "[13] V. Alves de Oliveira, M. Chabert, T. Oberlin, C. Poulliat, harnessing adversarial examples,” ArXiv preprint arXiv:\n",
      "M. Bruno, C. Latry & R. Camarero, 1412.6572, 2014.\n",
      "“Reduced-Complexity End-to-End Variational [29] R. Yamashita, M. Nishio, R. K. G. Do, et al.,\n",
      "Autoencoder for on Board Satellite Image Compression,” “Convolutional neural networks: an overview and\n",
      "Remote Sensing, vol. 13, no. 3, p. 447, 2021. application in radiology,” Insights Imaging, vol. 9, pp.\n",
      "[14] M. Ouahioune, S. Ameur & M. Lahdir, “Enhancing 611-629, 2018.\n",
      "hyperspectral image compression using learning-based [30] A. Habibian, T. V. Rozendaal, J. M. Tomczak & T. S.\n",
      "super-resolution technique,” Earth Science Informatics, Cohen, “Video compression with rate-distortion\n",
      "vol. 14, no. 3, pp. 1173-1183, 2021. autoencoders,” in Proceedings of the IEEE/CVF\n",
      "[15] W. Wang, D. Yang, F. Chen, Y. Pang, S. Huang & Y. Ge, International Conference on Computer Vision, pp.\n",
      "“Clustering With Orthogonal AutoEncoder,” IEEE 7033-7042, 2019.\n",
      "Access, vol. 7, pp. 62421-62432, 2019. [31] “Deep inside Autoencoders,” Towards Data Science,\n",
      "[16] V. H. Ayma, V. A. Ayma & J. Gutierrez, “Dimensionality available at: [Link].\n",
      "Reduction via an Orthogonal Autoencoder Approach for [32] W. Li, H. Fu, L. Yu, P. Gong, D. Feng, C. Li & N. Clinton,\n",
      "Hyperspectral Image Classification,” in International “Stacked Autoencoder-based deep learning for\n",
      "Archives of the Photogrammetry, Remote Sensing & remote-sensing image classification: a case study of\n",
      "Spatial Information Sciences, vol. 43, 2020. African land-cover mapping,” International journal of\n",
      "[17] J. Kuester, W. Gross & W. Middelmann, remote sensing, vol. 37, no. 23, pp. 5632-5646, 2016.\n",
      "“1D-Convolutional Autoencoder Based Hyperspectral [33] G. Abdi, F. Samadzadegan & P. Reinartz,\n",
      "Data Compression,” in The International Archives of “Spectral-spatial feature learning for hyperspectral\n",
      "Photogrammetry, Remote Sensing and Spatial imagery classification using deep stacked sparse\n",
      "Information Sciences, vol. 43, pp. 15-21, 2021. autoencoder,” Journal of Applied Remote Sensing, vol.\n",
      "[18] M. Kowsher, M. A. Alam, M. J. Uddin, F. Ahmed, M. W. 11, no. 4, p. 042604, 2017.\n",
      "Ullah & M. R. Islam, “Detecting Third Umpire Decisions [34] H. Fu, P. Lei, H. Tao, L. Zhao & J. Yang, “Improved\n",
      "& Automated Scoring System of Cricket,” in semi-supervised autoencoder for deception detection,”\n",
      "International Conference on Computer, Communication, PloS one, vol. 14, no. 10, p. e0223361, 2019.\n",
      "Chemical, Materials and Electronic Engineering [35] S. Saravanan & J. Sujitha, “Deep medical image\n",
      "(IC4ME2) , pp. 1-8, 2019. reconstruction with autoencoders using deep Boltzmann\n",
      "[19] K. O'Shea & R. Nash, “An introduction to convolutional machine training,” EAI Endorsed Transactions on\n",
      "neural networks,” ArXiv pre-print arXiv: 1511.08458, Pervasive Health and Technology, vol. 6, no. 24, p. e2,\n",
      "2015. 2020.\n",
      "[20] H. Kagaya, K. Aizawa & M. Ogawa, “Food detection and [36] L. Yasenko, Y. Klyatchenko & O.\n",
      "recognition using convolutional neural network,” in Tarasenko-Klyatchenko, “Image noise reduction by\n",
      "denoising autoencoder,” in IEEE 11th InternationalHyperspectral Image Compression using Modified Convolutional Autoencoder 407\n",
      "Conference on Dependable Systems, Services and recommendation systems, fraud detection, and\n",
      "Technologies (DESSERT), pp. 351-355, 2020. more.\n",
      "[37] K. Haribabu, G. R. K. S. Subrahmanyam & D. Mishra, “A\n",
      "robust digital image watermarking technique using Santwana Sagnika is an Assistant Professor\n",
      "autoencoder based convolutional neural networks,” in at School of Computer Engineering, KIIT\n",
      "IEEE Workshop on Computational Intelligence: Theories, Deemed to be University. She has completed\n",
      "Applications and Future Directions (WCI), pp. 1-6, 2015. her Ph.D. in Computer Science and\n",
      "[38] Y. Yang, Q. J. Wu & Y. Wang, “Autoencoder with Engineering from KIIT Deemed to be\n",
      "invertible functions for dimension reduction and image University, Bhubaneswar, India. Her areas of\n",
      "reconstruction,” IEEE Transactions on Systems, Man, interest include Natural Language Processing,\n",
      "and Cybernetics: Systems, vol. 48, no. 7, pp. 1065-1079, Machine Learning, Optimization techniques\n",
      "2018. and Cloud Computing. She has published more\n",
      "[39] W. Xu, S. Keshmiri, and G. Wang, “Adversarially than 25 papers in renowned journals and\n",
      "approximated autoencoder for image generation and conferences and is a regular reviewer for\n",
      "manipulation,” IEEE Transactions on Multimedia, vol. Springer, Elsevier, Taylor and Francis, and\n",
      "21, no. 9, pp. 2387-2396, 2019. SAGE journals.\n",
      "[40] “Autoencoder Image Compression with Keras,” Paper\n",
      "space, available at: [Link] Saurabh Bilgaiyan is currently working as an\n",
      "[41] “Hyperspectral Remote Sensing Scenes,” Center for Assistant Professor in KIIT deemed to be\n",
      "Coastal and Watershed Studies, available at: [Link] University, Bhubaneswar, India since 2016.\n",
      "[42] “The Attention Mechanism from Scratch,” Machine He has completed his Master's and Ph.D. in\n",
      "Learning Mastery, available at: [Link] Computer Science Engineering from KIIT,\n",
      "[43] “Flatten Layer - Keras Documentation,” Keras, available Deemed to be University, Bhubaneswar, India\n",
      "at: [Link] in 2014 and 2018 respectively. Bachelor’s\n",
      "[44] S. Issa and A. R. Khaled, “Lower Limb Activity degree of B.E. in Information Technology\n",
      "Prediction Using EMG Signals and Broad Learning,” from B.I.R.T., Bhopal, India in 2012. Dr.\n",
      "International Journal of Computer Information Systems Saurabh Bilgaiyan has published more than 50\n",
      "and Industrial Management Applications, vol. 14, pp. research papers in various reputed\n",
      "162-172, 2022. International Journals, Conferences, and\n",
      "[45] “Adam - Keras Documentation,” Keras, available at: edited books. His area of interest includes soft\n",
      "[Link] computing, software engineering, cloud\n",
      "[46] S. Dolgikh, “Generative Conceptual Representations and computing, image processing, and machine\n",
      "Semantic Communications,” International Journal of learning. He has reviewed various manuscripts\n",
      "Computer Information Systems and Industrial in more than 25 International conferences and\n",
      "Management Applications, vol. 14, pp. 239-248, 2022. Journals including Soft Computing Springer,\n",
      "IEEE Access, IETE Journal of Research\n",
      "Taylor and Francis, Future Generation\n",
      "Computer System Elsevier, Concurrency and\n",
      "Author Biographies\n",
      "Computation: Practice and Experience Wiley,\n",
      "Satvik Agrawal was born in Ajmer, Rajasthan, etc.\n",
      "India in the year 2001. He completed a\n",
      "majority of his schooling from Pune after\n",
      "Saksham Gupta, born in 1998, did most of his\n",
      "which he enrolled at Kalinga Institute of\n",
      "schooling and Bachelor's of Engineering in\n",
      "Industrial Technology, Bhubaneshwar to study\n",
      "computer science from Chandigarh. He then\n",
      "computer science engineering. He has worked\n",
      "shifted to Hyderabad in 2023 as a student in\n",
      "on numerous papers related to machine\n",
      "the Indian School of Business where he is\n",
      "learning and is on track to graduate with\n",
      "studying management. He has worked in the\n",
      "exemplary grades.\n",
      "fields of Computer Vision, Neural Networks\n",
      "and Machine Learning.\n",
      "Sancharika Debnath, a native of West\n",
      "Bengal, India, was born in 2001 and is\n",
      "currently in her final year of undergraduate\n",
      "studies at Kalinga Institute of Industrial\n",
      "Technology, pursuing a B.Tech. Degree in\n",
      "Information Technology. With a passion for\n",
      "cutting-edge technologies, her interests lie in\n",
      "various domains of the field, including\n",
      "Unsupervised Learning, Transfer Learning,\n",
      "Machine Learning, Deep Learning, and Web\n",
      "Development. She actively applies her\n",
      "knowledge and skills in these areas to tackle\n",
      "real-world challenges, such as text mining,\n"
     ]
    }
   ],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "query = \"who is tha publisher\"\n",
    "\n",
    "results = vector_index.similarity_search(query, k=1)\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C:\\Program Files\\Tesseract-OCR'\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def read_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "def read_text_from_pdf(pdf_path):\n",
    "    images = convert_from_path(pdf_path)\n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image_reader import read_text_from_image\n",
    "# from pdf_reader import read_text_from_pdf\n",
    "\n",
    "# Example usage for images\n",
    "image_path = \"12.jpg\"\n",
    "image_text = read_text_from_image(image_path)\n",
    "print(\"Text from image:\")\n",
    "print(image_text)\n",
    "\n",
    "# Example usage for PDFs\n",
    "# pdf_path = \"document.pdf\"\n",
    "# pdf_text = read_text_from_pdf(pdf_path)\n",
    "# print(\"Text from PDF:\")\n",
    "# print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
